---
title: "LangGraphå­¦ä¹ æ•™ç¨‹"
date: 2026-02-06
tags: [langgraph, ai, workflows, state-machines, python, tutorial]
category: AIæ¡†æ¶
status: è¿›è¡Œä¸­
difficulty: é«˜çº§
estimated_time: "4-6å‘¨"
last_updated: 2026-02-06
version: "0.1"
---

# LangGraphå­¦ä¹ æ•™ç¨‹

## ğŸ“– ç›®å½•
- [æ¦‚è¿°](#æ¦‚è¿°)
- [ä¸ºä»€ä¹ˆé€‰æ‹©LangGraph](#ä¸ºä»€ä¹ˆé€‰æ‹©langgraph)
- [å®‰è£…ä¸é…ç½®](#å®‰è£…ä¸é…ç½®)
- [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
- [åŸºç¡€ç»„ä»¶](#åŸºç¡€ç»„ä»¶)
- [çŠ¶æ€ç®¡ç†](#çŠ¶æ€ç®¡ç†)
- [å›¾ç»“æ„è®¾è®¡](#å›¾ç»“æ„è®¾è®¡)
- [å·¥ä½œæµç¨‹](#å·¥ä½œæµç¨‹)
- [å®é™…åº”ç”¨ç¤ºä¾‹](#å®é™…åº”ç”¨ç¤ºä¾‹)
- [é«˜çº§ç‰¹æ€§](#é«˜çº§ç‰¹æ€§)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [æ‰©å±•èµ„æº](#æ‰©å±•èµ„æº)

---

## ğŸ¯ æ¦‚è¿°

LangGraphæ˜¯LangChainç”Ÿæ€ç³»ç»Ÿä¸­çš„ä¸€ä¸ªå¼ºå¤§æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºæ„å»º**å¤æ‚çš„æœ‰çŠ¶æ€å¤šAgentåº”ç”¨**ã€‚å®ƒåŸºäº**çŠ¶æ€å›¾ï¼ˆStateGraphï¼‰**çš„æ¦‚å¿µï¼Œå…è®¸å¼€å‘è€…åˆ›å»ºåŠ¨æ€ã€å¯æ§çš„AIå·¥ä½œæµã€‚

### æ ¸å¿ƒç‰¹æ€§
- **çŠ¶æ€åŒ–å·¥ä½œæµ**: æ¯ä¸ªèŠ‚ç‚¹éƒ½ç»´æŠ¤å’Œæ›´æ–°åº”ç”¨çŠ¶æ€
- **æ¡ä»¶åˆ†æ”¯**: æ ¹æ®çŠ¶æ€åŠ¨æ€å†³å®šä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹
- **å¤šAgentåè°ƒ**: è½»æ¾ç®¡ç†å¤šä¸ªAgentä¹‹é—´çš„äº¤äº’
- **å¯è§‚å¯Ÿæ€§**: å†…ç½®çš„è°ƒè¯•å’Œç›‘æ§åŠŸèƒ½
- **å¯æ‰©å±•æ€§**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•å’Œå®šåˆ¶

### åº”ç”¨åœºæ™¯
- **å¤šæ­¥éª¤AIä»»åŠ¡**: éœ€è¦å¤šè½®å¯¹è¯å’Œæ¨ç†çš„å¤æ‚ä»»åŠ¡
- **Agentå›¢é˜Ÿåä½œ**: å¤šä¸ªä¸“ä¸šåŒ–AgentååŒå·¥ä½œ
- **åŠ¨æ€å†³ç­–æµç¨‹**: éœ€è¦æ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´æ‰§è¡Œè·¯å¾„
- **ä¸šåŠ¡æµç¨‹è‡ªåŠ¨åŒ–**: AIé©±åŠ¨çš„ä¸šåŠ¡æµç¨‹å’Œå·¥ä½œæµ

---

## ğŸ¤” ä¸ºä»€ä¹ˆé€‰æ‹©LangGraph

### vs ä¼ ç»ŸLangChain Chain

| ç‰¹æ€§ | LangChain Chain | LangGraph |
|------|-----------------|-----------|
| **çŠ¶æ€ç®¡ç†** | æ— çŠ¶æ€æˆ–æœ‰é™çŠ¶æ€ | å®Œæ•´çŠ¶æ€ç®¡ç† |
| **åˆ†æ”¯é€»è¾‘** | çº¿æ€§æµç¨‹ | åŠ¨æ€æ¡ä»¶åˆ†æ”¯ |
| **Agentåè°ƒ** | å›°éš¾ | è‡ªç„¶æ”¯æŒ |
| **é”™è¯¯å¤„ç†** | åŸºç¡€ | é«˜çº§é”™è¯¯æ¢å¤ |
| **è°ƒè¯•æ€§** | æœ‰é™ | å®Œæ•´æ‰§è¡Œè¿½è¸ª |
| **å¤æ‚åº¦** | ç®€å•ä»»åŠ¡ | å¤æ‚å·¥ä½œæµ |

### ä¸»è¦ä¼˜åŠ¿

#### 1. **çŠ¶æ€æ„ŸçŸ¥**
```python
# LangChain - æ— çŠ¶æ€
result = chain.run("ç”¨æˆ·è¾“å…¥")

# LangGraph - æœ‰çŠ¶æ€
state = graph.invoke({"messages": ["ç”¨æˆ·è¾“å…¥"]})
# çŠ¶æ€åœ¨æ•´ä¸ªæ‰§è¡Œè¿‡ç¨‹ä¸­è¢«ç»´æŠ¤å’Œæ›´æ–°
```

#### 2. **åŠ¨æ€è·¯ç”±**
```python
# æ ¹æ®æ¡ä»¶åŠ¨æ€é€‰æ‹©ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
def route_after_analysis(state):
    if state["confidence"] > 0.8:
        return "high_confidence"
    elif state["needs_human"] == True:
        return "human_review"
    else:
        return "additional_research"
```

#### 3. **Agentç¼–æ’**
```python
# å¤šAgentåä½œ
researcher_agent = create_researcher_agent()
writer_agent = create_writer_agent()
reviewer_agent = create_reviewer_agent()

# Agenté—´çš„çŠ¶æ€ä¼ é€’
def research_step(state):
    # Researcherå®Œæˆç ”ç©¶ï¼Œæ›´æ–°çŠ¶æ€
    return {"research_data": researcher_agent.run(state["topic"])}

def write_step(state):
    # WriteråŸºäºresearch_dataå†™ä½œ
    return {"draft": writer_agent.run(state["research_data"])}

def review_step(state):
    # Reviewerå®¡é˜…å¹¶å†³å®šä¸‹ä¸€æ­¥
    feedback = reviewer_agent.run(state["draft"])
    return {"feedback": feedback, "approved": feedback["score"] > 8}
```

---

## âš™ï¸ å®‰è£…ä¸é…ç½®

### åŸºæœ¬å®‰è£…

```bash
# å®‰è£…LangGraph
pip install langgraph

# æˆ–ä½¿ç”¨conda
conda install -c conda-forge langgraph

# éªŒè¯å®‰è£…
python -c "import langgraph; print(langgraph.__version__)"
```

### å®Œæ•´å®‰è£…ï¼ˆå«å¯é€‰ä¾èµ–ï¼‰

```bash
pip install langgraph[all]

# åŒ…å«çš„ä¾èµ–ï¼š
# - langchain: æ ¸å¿ƒæ¡†æ¶
# - langchain-community: ç¤¾åŒºé›†æˆ
# - langchain-core: æ ¸å¿ƒç»„ä»¶
# - pydantic: æ•°æ®éªŒè¯
# - python-dotenv: ç¯å¢ƒå˜é‡ç®¡ç†
```

### ç¯å¢ƒé…ç½®

```bash
# .envæ–‡ä»¶
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_key
LANGCHAIN_PROJECT=langgraph-tutorial
```

### åŸºæœ¬æµ‹è¯•

```python
import os
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated
import operator

# æ£€æŸ¥å®‰è£…
print("LangGraphç‰ˆæœ¬:", __import__langgraph__).__version__)

# åˆ›å»ºç®€å•çš„çŠ¶æ€å›¾
class AgentState(TypedDict):
    messages: Annotated[list, operator.add]

def test_graph():
    graph = StateGraph(AgentState)

    def node_1(state):
        return {"messages": ["Node 1 processed"]}

    def node_2(state):
        return {"messages": ["Node 2 processed"]}

    graph.add_node("node_1", node_1)
    graph.add_node("node_2", node_2)
    graph.add_edge("node_1", "node_2")
    graph.add_edge("node_2", END)

    app = graph.compile()

    result = app.invoke({"messages": []})
    print("æµ‹è¯•ç»“æœ:", result)

test_graph()
```

---

## ğŸ—ï¸ æ ¸å¿ƒæ¦‚å¿µ

### 1. StateGraphï¼ˆçŠ¶æ€å›¾ï¼‰

StateGraphæ˜¯LangGraphçš„æ ¸å¿ƒæ¦‚å¿µï¼Œå®ƒå®šä¹‰äº†ä¸€ä¸ª**æœ‰çŠ¶æ€çš„å·¥ä½œæµ**ï¼š

```python
from langgraph.graph import StateGraph
from typing import TypedDict

class MyState(TypedDict):
    current_step: str
    data: dict
    messages: list[str]

# åˆ›å»ºçŠ¶æ€å›¾
graph = StateGraph(MyState)

# æ·»åŠ èŠ‚ç‚¹å’Œè¾¹
graph.add_node("start", start_node)
graph.add_node("process", process_node)
graph.add_node("end", end_node)

graph.add_edge("start", "process")
graph.add_edge("process", "end")
graph.add_edge("end", END)
```

### 2. Nodesï¼ˆèŠ‚ç‚¹ï¼‰

èŠ‚ç‚¹æ˜¯å·¥ä½œæµä¸­çš„**å¤„ç†å•å…ƒ**ï¼Œå¯ä»¥æ˜¯å‡½æ•°ã€ç±»æˆ–Agentï¼š

```python
# å‡½æ•°å¼èŠ‚ç‚¹
def research_node(state: MyState) -> MyState:
    """ç ”ç©¶æ­¥éª¤èŠ‚ç‚¹"""
    topic = state["data"]["topic"]
    research = perform_research(topic)

    return {
        "current_step": "research",
        "data": {**state["data"], "research": research}
    }

# AgentèŠ‚ç‚¹
from langchain.agents import create_openai_functions_agent

def agent_node(state: MyState, agent, prompt) -> MyState:
    """Agentå¤„ç†èŠ‚ç‚¹"""
    response = agent.invoke({
        "input": state["data"]["question"],
        "chat_history": state["messages"]
    })

    return {
        "messages": state["messages"] + [response["output"]],
        "data": {**state["data"], "last_response": response}
    }
```

### 3. Edgesï¼ˆè¾¹ï¼‰

è¾¹å®šä¹‰èŠ‚ç‚¹é—´çš„**è¿æ¥å…³ç³»**ï¼š

```python
# å›ºå®šè¾¹
graph.add_edge("node_a", "node_b")

# æ¡ä»¶è¾¹
def route_function(state: MyState) -> str:
    if state["confidence"] > 0.8:
        return "high_confidence_path"
    else:
        return "low_confidence_path"

graph.add_conditional_edges(
    "decision_node",
    route_function,
    {
        "high_confidence_path": "approve_node",
        "low_confidence_path": "review_node"
    }
)
```

### 4. Stateï¼ˆçŠ¶æ€ï¼‰

çŠ¶æ€æ˜¯**åœ¨æ•´ä¸ªå·¥ä½œæµä¸­ç»´æŠ¤çš„æ•°æ®ç»“æ„**ï¼š

```python
from typing import TypedDict, List, Dict, Any, Optional
from typing_extensions import Annotated
import operator

class WorkflowState(TypedDict):
    # åŸºæœ¬çŠ¶æ€
    current_step: str
    messages: Annotated[List[str], operator.add]

    # ä¸šåŠ¡æ•°æ®
    user_query: str
    research_data: Optional[Dict[str, Any]]
    analysis_result: Optional[Dict[str, Any]]

    # æ§åˆ¶æµ
    confidence: float
    needs_human_review: bool
    error_count: int

    # å…ƒæ•°æ®
    metadata: Dict[str, Any]
    step_count: int

def update_state(state: WorkflowState, updates: Dict[str, Any]) -> WorkflowState:
    """çŠ¶æ€æ›´æ–°å‡½æ•°"""
    return {
        **state,
        **updates,
        "step_count": state["step_count"] + 1,
        "metadata": {**state["metadata"], "last_update": updates.get("current_step")}
    }
```

---

## ğŸ§© åŸºç¡€ç»„ä»¶

### 1. èŠ‚ç‚¹ç±»å‹

#### A. Function Nodeï¼ˆå‡½æ•°èŠ‚ç‚¹ï¼‰

```python
def simple_node(state: MyState) -> MyState:
    """ç®€å•å‡½æ•°èŠ‚ç‚¹"""
    return {
        "current_step": "completed",
        "messages": state["messages"] + ["å¤„ç†å®Œæˆ"]
    }

# æ·»åŠ åˆ°å›¾
graph.add_node("process", simple_node)
```

#### B. Agent Nodeï¼ˆAgentèŠ‚ç‚¹ï¼‰

```python
from langchain.agents import create_openai_functions_agent
from langchain.tools import Tool
from langchain.prompts import PromptTemplate

def create_researcher_agent():
    """åˆ›å»ºç ”ç©¶Agent"""
    tools = [
        Tool(
            name="web_search",
            description="æœç´¢ç½‘ç»œä¿¡æ¯",
            func=web_search_tool
        ),
        Tool(
            name="data_analysis",
            description="åˆ†ææ•°æ®",
            func=analyze_data_tool
        )
    ]

    prompt = PromptTemplate.from_template("""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶åŠ©æ‰‹ã€‚

    ä»»åŠ¡ï¼š{task}
    å½“å‰ä¸Šä¸‹æ–‡ï¼š{context}

    è¯·ä½¿ç”¨å¯ç”¨çš„å·¥å…·è¿›è¡Œç ”ç©¶ï¼Œå¹¶å°†ç»“æœä»¥ç»“æ„åŒ–æ ¼å¼è¿”å›ã€‚
    """)

    agent = create_openai_functions_agent(
        llm=llm,
        tools=tools,
        prompt=prompt
    )

    return agent

def research_agent_node(state: WorkflowState) -> WorkflowState:
    """ç ”ç©¶AgentèŠ‚ç‚¹"""
    agent = create_researcher_agent()

    response = agent.invoke({
        "task": state["user_query"],
        "context": str(state.get("metadata", {}))
    })

    return {
        **state,
        "current_step": "research",
        "research_data": parse_research_response(response["output"]),
        "messages": state["messages"] + [f"ç ”ç©¶å®Œæˆ: {response['output']}"]
    }

graph.add_node("research", research_agent_node)
```

#### C. Router Nodeï¼ˆè·¯ç”±å™¨èŠ‚ç‚¹ï¼‰

```python
def intelligent_router(state: WorkflowState) -> str:
    """æ™ºèƒ½è·¯ç”±å™¨èŠ‚ç‚¹"""
    query = state["user_query"].lower()
    confidence = state["confidence"]

    # æ ¹æ®æŸ¥è¯¢ç±»å‹è·¯ç”±
    if any(keyword in query for keyword in ["æœç´¢", "æŸ¥æ‰¾", "ä»€ä¹ˆ"]):
        return "search"
    elif any(keyword in query for keyword in ["è®¡ç®—", "æ•°å­¦", "ç­‰äº"]):
        return "calculate"
    elif any(keyword in query for keyword in ["åˆ†æ", "æ¯”è¾ƒ", "è¯„ä¼°"]):
        return "analyze"
    elif confidence < 0.7:
        return "clarify"
    else:
        return "general_processing"

graph.add_conditional_edges(
    "router",
    intelligent_router,
    {
        "search": "web_search",
        "calculate": "calculator",
        "analyze": "data_analysis",
        "clarify": "human_input",
        "general_processing": "llm_processing"
    }
)
```

### 2. è¾¹ç±»å‹

#### A. å›ºå®šè¾¹ï¼ˆFixed Edgesï¼‰

```python
# ç®€å•çš„çº¿æ€§æµç¨‹
graph.add_edge("start", "process")
graph.add_edge("process", "review")
graph.add_edge("review", "end")
```

#### B. æ¡ä»¶è¾¹ï¼ˆConditional Edgesï¼‰

```python
def quality_check(state: WorkflowState) -> str:
    """è´¨é‡æ£€æŸ¥è·¯ç”±å™¨"""
    score = state.get("quality_score", 0)
    human_review_needed = state.get("needs_human_review", False)

    if human_review_needed:
        return "human_review"
    elif score >= 8.0:
        return "approve"
    elif score >= 6.0:
        return "revision"
    else:
        return "reject"

# æ·»åŠ æ¡ä»¶è¾¹
graph.add_conditional_edges(
    "quality_check",
    quality_check,
    {
        "human_review": "human_input",
        "approve": "finalize",
        "revision": "improve",
        "reject": "restart"
    }
)
```

#### C. å¾ªç¯è¾¹ï¼ˆLoop Edgesï¼‰

```python
def should_continue(state: WorkflowState) -> bool:
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­å¾ªç¯"""
    max_iterations = state.get("max_iterations", 5)
    current_iteration = state.get("step_count", 0)

    # ç»§ç»­æ¡ä»¶
    should_continue = (
        current_iteration < max_iterations and
        state.get("needs_improvement", True) and
        not state.get("converged", False)
    )

    return should_continue

# åˆ›å»ºå¾ªç¯
graph.add_edge("improve", "quality_check")
graph.add_edge("quality_check", "finalize", condition=should_continue)
```

### 3. ç‰¹æ®ŠèŠ‚ç‚¹

#### A. é”™è¯¯å¤„ç†èŠ‚ç‚¹

```python
def error_handler(state: WorkflowState, error: Exception) -> WorkflowState:
    """é”™è¯¯å¤„ç†èŠ‚ç‚¹"""
    error_count = state.get("error_count", 0) + 1

    # æ ¹æ®é”™è¯¯ç±»å‹å†³å®šå¤„ç†ç­–ç•¥
    if isinstance(error, TimeoutError):
        strategy = "retry_with_timeout"
    elif isinstance(error, ValueError):
        strategy = "validate_input"
    elif isinstance(error, ConnectionError):
        strategy = "retry_with_backoff"
    else:
        strategy = "escalate_to_human"

    return {
        **state,
        "current_step": "error_handling",
        "error": str(error),
        "error_count": error_count,
        "recovery_strategy": strategy,
        "needs_improvement": True
    }

# æ·»åŠ é”™è¯¯å¤„ç†
graph.add_node("handle_error", error_handler)
```

#### B. äººå·¥å¹²é¢„èŠ‚ç‚¹

```python
def human_intervention(state: WorkflowState) -> WorkflowState:
    """äººå·¥å¹²é¢„èŠ‚ç‚¹"""
    print("éœ€è¦äººå·¥å¹²é¢„:")
    print(f"å½“å‰çŠ¶æ€: {state}")

    # è¿™é‡Œå¯ä»¥é›†æˆUIç•Œé¢æˆ–èŠå¤©ç•Œé¢
    user_input = input("è¯·æä¾›è¾“å…¥ (æˆ–è¾“å…¥ 'skip' è·³è¿‡): ")

    if user_input.lower() == 'skip':
        return {**state, "human_input": None, "skipped": True}
    else:
        return {
            **state,
            "human_input": user_input,
            "needs_human_review": False
        }

graph.add_node("human_review", human_intervention)
```

---

## ğŸ’¾ çŠ¶æ€ç®¡ç†

### 1. çŠ¶æ€ç»“æ„è®¾è®¡

#### åŸºç¡€çŠ¶æ€ç±»

```python
from typing import TypedDict, List, Dict, Any, Optional
from typing_extensions import Annotated
import operator

class BaseWorkflowState(TypedDict):
    # å¿…éœ€å­—æ®µ
    current_step: str
    messages: Annotated[List[str], operator.add]

    # å¯é€‰å­—æ®µ
    user_id: Optional[str]
    session_id: Optional[str]
    timestamp: Optional[str]

# æ‰©å±•çŠ¶æ€
class ResearchWorkflowState(BaseWorkflowState):
    # ä¸šåŠ¡æ•°æ®
    research_topic: str
    research_data: Optional[Dict[str, Any]]
    sources: List[str]

    # åˆ†æç»“æœ
    analysis: Optional[Dict[str, Any]]
    confidence_score: float

    # æ§åˆ¶æµ
    requires_human_review: bool
    revision_count: int
    max_revisions: int

    # è´¨é‡æ§åˆ¶
    quality_score: Optional[float]
    plagiarism_check: Optional[bool]
    fact_check_status: Optional[str]
```

#### çŠ¶æ€æ›´æ–°å™¨

```python
def create_state_updater(state_class):
    """åˆ›å»ºçŠ¶æ€æ›´æ–°å™¨"""
    def update_state(current_state: Dict[str, Any], updates: Dict[str, Any]) -> Dict[str, Any]:
        # éªŒè¯æ›´æ–°
        validated_updates = validate_updates(updates, state_class)

        # åˆå¹¶çŠ¶æ€
        new_state = {**current_state, **validated_updates}

        # æ·»åŠ å…ƒæ•°æ®
        if "step_count" not in new_state:
            new_state["step_count"] = 0

        new_state["step_count"] += 1
        new_state["last_updated"] = str(datetime.now())

        return new_state

    return update_state

def validate_updates(updates: Dict[str, Any], state_class) -> Dict[str, Any]:
    """éªŒè¯çŠ¶æ€æ›´æ–°"""
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„éªŒè¯é€»è¾‘
    validated = {}

    for key, value in updates.items():
        # åŸºæœ¬ç±»å‹æ£€æŸ¥
        if key in state_class.__annotations__:
            expected_type = state_class.__annotations__[key]

            if isinstance(expected_type._name, str) and expected_type._name.startswith("Optional"):
                if value is not None:
                    validated[key] = value
            elif isinstance(expected_type, type):
                if isinstance(value, expected_type):
                    validated[key] = value
                else:
                    raise ValueError(f"ç±»å‹ä¸åŒ¹é…: {key}")
            else:
                validated[key] = value
        else:
            # å…è®¸é¢å¤–çš„å­—æ®µ
            validated[key] = value

    return validated
```

### 2. çŠ¶æ€æŒä¹…åŒ–

#### å†…å­˜å­˜å‚¨

```python
from typing import Union
import json
import uuid
from datetime import datetime

class InMemoryStateStore:
    """å†…å­˜çŠ¶æ€å­˜å‚¨"""

    def __init__(self):
        self.states: Dict[str, Dict[str, Any]] = {}

    def save_state(self, session_id: str, state: Dict[str, Any]) -> None:
        """ä¿å­˜çŠ¶æ€"""
        self.states[session_id] = {
            **state,
            "saved_at": datetime.now().isoformat()
        }

    def load_state(self, session_id: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½çŠ¶æ€"""
        return self.states.get(session_id)

    def delete_state(self, session_id: str) -> bool:
        """åˆ é™¤çŠ¶æ€"""
        if session_id in self.states:
            del self.states[session_id]
            return True
        return False

    def list_sessions(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰ä¼šè¯"""
        return list(self.states.keys())

# å…¨å±€çŠ¶æ€å­˜å‚¨å®ä¾‹
state_store = InMemoryStateStore()

def with_persistence(func):
    """çŠ¶æ€æŒä¹…åŒ–è£…é¥°å™¨"""
    def wrapper(state: Dict[str, Any], *args, **kwargs):
        session_id = state.get("session_id", str(uuid.uuid4()))

        # åŠ è½½ä¹‹å‰çš„çŠ¶æ€
        previous_state = state_store.load_state(session_id)
        if previous_state:
            state = {**previous_state, **state}

        # æ‰§è¡Œå‡½æ•°
        result = func(state, *args, **kwargs)

        # ä¿å­˜æ–°çŠ¶æ€
        state_store.save_state(session_id, result)

        return result

    return wrapper

# ä½¿ç”¨ç¤ºä¾‹
@with_persistence
def persistent_node(state: WorkflowState) -> WorkflowState:
    """æŒä¹…åŒ–èŠ‚ç‚¹"""
    return {
        **state,
        "current_step": "processed",
        "messages": state["messages"] + ["çŠ¶æ€å·²æŒä¹…åŒ–"]
    }
```

#### Rediså­˜å‚¨

```python
import redis
import json
from typing import Any

class RedisStateStore:
    """RedisçŠ¶æ€å­˜å‚¨"""

    def __init__(self, host='localhost', port=6379, db=0):
        self.redis_client = redis.Redis(host=host, port=port, db=db)

    def save_state(self, session_id: str, state: Dict[str, Any], ttl: int = 3600) -> None:
        """ä¿å­˜çŠ¶æ€åˆ°Redis"""
        serialized_state = json.dumps(state, default=str)
        self.redis_client.setex(
            f"langgraph:{session_id}",
            ttl,
            serialized_state
        )

    def load_state(self, session_id: str) -> Optional[Dict[str, Any]]:
        """ä»RedisåŠ è½½çŠ¶æ€"""
        serialized_state = self.redis_client.get(f"langgraph:{session_id}")
        if serialized_state:
            try:
                return json.loads(serialized_state)
            except json.JSONDecodeError:
                return None
        return None

    def delete_state(self, session_id: str) -> bool:
        """ä»Redisåˆ é™¤çŠ¶æ€"""
        return bool(self.redis_client.delete(f"langgraph:{session_id}"))

# RedisçŠ¶æ€å­˜å‚¨
redis_store = RedisStateStore()

def with_redis_persistence(ttl: int = 3600):
    """RedisæŒä¹…åŒ–è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(state: Dict[str, Any], *args, **kwargs):
            session_id = state.get("session_id")
            if not session_id:
                return func(state, *args, **kwargs)

            # åŠ è½½ä¹‹å‰çš„çŠ¶æ€
            previous_state = redis_store.load_state(session_id)
            if previous_state:
                state = {**previous_state, **state}

            # æ‰§è¡Œå‡½æ•°
            result = func(state, *args, **kwargs)

            # ä¿å­˜æ–°çŠ¶æ€
            redis_store.save_state(session_id, result, ttl)

            return result

        return wrapper
    return decorator
```

### 3. çŠ¶æ€éªŒè¯

```python
from pydantic import BaseModel, validator, Field
from typing import Optional

class WorkflowStateModel(BaseModel):
    """çŠ¶æ€éªŒè¯æ¨¡å‹"""
    current_step: str = Field(..., min_length=1)
    messages: List[str] = Field(default_factory=list)

    research_topic: Optional[str] = None
    confidence_score: float = Field(default=0.0, ge=0.0, le=1.0)
    requires_human_review: bool = Field(default=False)

    class Config:
        extra = "allow"  # å…è®¸é¢å¤–å­—æ®µ

    @validator('current_step')
    def validate_step(cls, v):
        allowed_steps = [
            'start', 'research', 'analysis', 'review',
            'revision', 'finalize', 'error', 'end'
        ]
        if v not in allowed_steps:
            raise ValueError(f'æ— æ•ˆçš„æ­¥éª¤: {v}')
        return v

def validate_state(state: Dict[str, Any]) -> Dict[str, Any]:
    """éªŒè¯çŠ¶æ€"""
    try:
        validated_model = WorkflowStateModel(**state)
        return validated_model.dict()
    except Exception as e:
        raise ValueError(f"çŠ¶æ€éªŒè¯å¤±è´¥: {e}")

# åœ¨èŠ‚ç‚¹ä¸­ä½¿ç”¨éªŒè¯
def validated_research_node(state: WorkflowState) -> WorkflowState:
    """å¸¦éªŒè¯çš„ç ”ç©¶èŠ‚ç‚¹"""
    # éªŒè¯è¾“å…¥çŠ¶æ€
    validated_state = validate_state(state)

    # æ‰§è¡Œå¤„ç†
    result = perform_research(validated_state["research_topic"])

    # éªŒè¯è¾“å‡ºçŠ¶æ€
    output_state = {
        **validated_state,
        "current_step": "research",
        "research_data": result,
        "messages": validated_state["messages"] + ["ç ”ç©¶å®Œæˆ"]
    }

    return validate_state(output_state)
```

---

## ğŸ”€ å›¾ç»“æ„è®¾è®¡

### 1. çº¿æ€§å›¾ï¼ˆLinear Graphï¼‰

æœ€ç®€å•çš„å›¾ç»“æ„ï¼ŒèŠ‚ç‚¹æŒ‰é¡ºåºæ‰§è¡Œï¼š

```python
from langgraph.graph import StateGraph, END

def create_linear_workflow():
    """åˆ›å»ºçº¿æ€§å·¥ä½œæµ"""
    graph = StateGraph(WorkflowState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("start", start_node)
    graph.add_node("research", research_node)
    graph.add_node("analyze", analyze_node)
    graph.add_node("write", write_node)
    graph.add_node("review", review_node)
    graph.add_node("finalize", finalize_node)

    # æ·»åŠ è¾¹
    graph.add_edge("start", "research")
    graph.add_edge("research", "analyze")
    graph.add_edge("analyze", "write")
    graph.add_edge("write", "review")
    graph.add_edge("review", "finalize")
    graph.add_edge("finalize", END)

    # è®¾ç½®å…¥å£ç‚¹
    graph.set_entry_point("start")

    return graph.compile()

# èŠ‚ç‚¹å®šä¹‰
def start_node(state: WorkflowState) -> WorkflowState:
    return {
        **state,
        "current_step": "start",
        "messages": state["messages"] + ["å·¥ä½œæµå¼€å§‹"]
    }

def research_node(state: WorkflowState) -> WorkflowState:
    # æ‰§è¡Œç ”ç©¶
    research_data = perform_research(state["research_topic"])
    return {
        **state,
        "current_step": "research",
        "research_data": research_data,
        "messages": state["messages"] + ["ç ”ç©¶å®Œæˆ"]
    }

# å…¶ä»–èŠ‚ç‚¹ç±»ä¼¼å®šä¹‰...
```

### 2. åˆ†æ”¯å›¾ï¼ˆBranch Graphï¼‰

æ”¯æŒæ ¹æ®æ¡ä»¶é€‰æ‹©ä¸åŒè·¯å¾„ï¼š

```python
def create_branching_workflow():
    """åˆ›å»ºåˆ†æ”¯å·¥ä½œæµ"""
    graph = StateGraph(WorkflowState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("classify", classify_query_node)
    graph.add_node("research", research_node)
    graph.add_node("calculate", calculator_node)
    graph.add_node("analyze", analyze_node)
    graph.add_node("search", search_node)
    graph.add_node("general", general_llm_node)
    graph.add_node("finalize", finalize_node)

    # è®¾ç½®å…¥å£ç‚¹
    graph.set_entry_point("classify")

    # æ·»åŠ æ¡ä»¶åˆ†æ”¯
    def route_by_type(state: WorkflowState) -> str:
        query_type = state.get("query_type", "general")

        type_mapping = {
            "research": "research",
            "calculation": "calculate",
            "analysis": "analyze",
            "search": "search",
            "general": "general"
        }

        return type_mapping.get(query_type, "general")

    graph.add_conditional_edges(
        "classify",
        route_by_type,
        {
            "research": "research",
            "calculate": "calculate",
            "analyze": "analyze",
            "search": "search",
            "general": "general"
        }
    )

    # æ‰€æœ‰åˆ†æ”¯éƒ½æ±‡èšåˆ°finalize
    for node in ["research", "calculate", "analyze", "search", "general"]:
        graph.add_edge(node, "finalize")

    graph.add_edge("finalize", END)

    return graph.compile()

def classify_query_node(state: WorkflowState) -> WorkflowState:
    """æŸ¥è¯¢åˆ†ç±»èŠ‚ç‚¹"""
    query = state["user_query"]

    # ç®€å•çš„åˆ†ç±»é€»è¾‘
    if any(word in query.lower() for word in ["ç ”ç©¶", "è°ƒæŸ¥", "åˆ†æ"]):
        query_type = "research"
    elif any(word in query.lower() for word in ["è®¡ç®—", "æ•°å­¦", "ç­‰äº", "+", "-", "*", "/"]):
        query_type = "calculation"
    elif any(word in query.lower() for word in ["æ¯”è¾ƒ", "è¯„ä¼°", "åˆ†æ"]):
        query_type = "analysis"
    elif any(word in query.lower() for word in ["æœç´¢", "æŸ¥æ‰¾", "ä»€ä¹ˆ"]):
        query_type = "search"
    else:
        query_type = "general"

    return {
        **state,
        "current_step": "classify",
        "query_type": query_type,
        "messages": state["messages"] + [f"æŸ¥è¯¢ç±»å‹: {query_type}"]
    }
```

### 3. å¾ªç¯å›¾ï¼ˆLoop Graphï¼‰

æ”¯æŒè¿­ä»£å¤„ç†ï¼Œç›´åˆ°æ»¡è¶³ç»ˆæ­¢æ¡ä»¶ï¼š

```python
def create_iterative_workflow():
    """åˆ›å»ºè¿­ä»£å·¥ä½œæµ"""
    graph = StateGraph(WorkflowState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("analyze", analyze_node)
    graph.add_node("improve", improve_node)
    graph.add_node("review", quality_check_node)
    graph.add_node("finalize", finalize_node)

    # è®¾ç½®å…¥å£ç‚¹
    graph.set_entry_point("analyze")

    # æ¡ä»¶è¾¹ç”¨äºå¾ªç¯
    def should_continue_loop(state: WorkflowState) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­å¾ªç¯"""
        iteration_count = state.get("iteration_count", 0)
        max_iterations = state.get("max_iterations", 3)
        quality_score = state.get("quality_score", 0)

        if iteration_count >= max_iterations:
            return "finalize"
        elif quality_score >= 8.0:
            return "finalize"
        else:
            return "improve"

    # æ·»åŠ å¾ªç¯è¾¹
    graph.add_conditional_edges(
        "review",
        should_continue_loop,
        {
            "improve": "improve",
            "finalize": "finalize"
        }
    )

    # æ”¹è¿›åå›åˆ°åˆ†æ
    graph.add_edge("improve", "analyze")
    graph.add_edge("analyze", "review")
    graph.add_edge("finalize", END)

    return graph.compile()

def quality_check_node(state: WorkflowState) -> WorkflowState:
    """è´¨é‡æ£€æŸ¥èŠ‚ç‚¹"""
    iteration_count = state.get("iteration_count", 0)

    # æ¨¡æ‹Ÿè´¨é‡è¯„åˆ†
    quality_score = min(9.0 - iteration_count * 1.5, 10.0)

    return {
        **state,
        "current_step": "review",
        "quality_score": quality_score,
        "iteration_count": iteration_count + 1,
        "messages": state["messages"] + [
            f"ç¬¬{iteration_count + 1}æ¬¡è¿­ä»£ï¼Œè´¨é‡è¯„åˆ†: {quality_score:.1f}"
        ]
    }

def improve_node(state: WorkflowState) -> WorkflowState:
    """æ”¹è¿›èŠ‚ç‚¹"""
    quality_score = state["quality_score"]
    current_output = state.get("current_output", "")

    # åŸºäºè´¨é‡åˆ†æ•°å†³å®šæ”¹è¿›ç­–ç•¥
    if quality_score < 5.0:
        strategy = "major_revision"
        improvement = "è¿›è¡Œé‡å¤§ä¿®æ”¹"
    elif quality_score < 7.0:
        strategy = "minor_revision"
        improvement = "è¿›è¡Œå°å¹…è°ƒæ•´"
    else:
        strategy = "fine_tuning"
        improvement = "è¿›è¡Œç²¾ç»†è°ƒä¼˜"

    return {
        **state,
        "current_step": "improve",
        "improvement_strategy": strategy,
        "current_output": current_output + f"\n[{strategy}] {improvement}",
        "messages": state["messages"] + [f"æ”¹è¿›ç­–ç•¥: {improvement}"]
    }
```

### 4. å¹¶è¡Œå›¾ï¼ˆParallel Graphï¼‰

æ”¯æŒå¹¶è¡Œæ‰§è¡Œå¤šä¸ªåˆ†æ”¯ï¼š

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List

def create_parallel_workflow():
    """åˆ›å»ºå¹¶è¡Œå·¥ä½œæµ"""
    graph = StateGraph(WorkflowState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("parallel_research", parallel_research_node)
    graph.add_node("synthesize", synthesize_results_node)
    graph.add_node("finalize", finalize_node)

    # è®¾ç½®å…¥å£ç‚¹
    graph.set_entry_point("parallel_research")

    # æ·»åŠ è¾¹
    graph.add_edge("parallel_research", "synthesize")
    graph.add_edge("synthesize", "finalize")
    graph.add_edge("finalize", END)

    return graph.compile()

def parallel_research_node(state: WorkflowState) -> WorkflowState:
    """å¹¶è¡Œç ”ç©¶èŠ‚ç‚¹"""
    research_topics = state.get("research_topics", [])

    if not research_topics:
        return {
            **state,
            "current_step": "parallel_research",
            "research_results": {},
            "messages": state["messages"] + ["æ²¡æœ‰ç ”ç©¶ä¸»é¢˜"]
        }

    # å¹¶è¡Œæ‰§è¡Œç ”ç©¶
    research_results = {}

    with ThreadPoolExecutor(max_workers=3) as executor:
        # æäº¤æ‰€æœ‰ç ”ç©¶ä»»åŠ¡
        future_to_topic = {
            executor.submit(perform_research, topic): topic
            for topic in research_topics
        }

        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_topic):
            topic = future_to_topic[future]
            try:
                result = future.result()
                research_results[topic] = result
            except Exception as e:
                research_results[topic] = {"error": str(e)}

    return {
        **state,
        "current_step": "parallel_research",
        "research_results": research_results,
        "messages": state["messages"] + [
            f"å¹¶è¡Œç ”ç©¶å®Œæˆï¼Œå¤„ç†äº†{len(research_topics)}ä¸ªä¸»é¢˜"
        ]
    }

def synthesize_results_node(state: WorkflowState) -> WorkflowState:
    """ç»¼åˆç»“æœèŠ‚ç‚¹"""
    research_results = state.get("research_results", {})

    # ç»¼åˆæ‰€æœ‰ç ”ç©¶ç»“æœ
    synthesis = []
    for topic, result in research_results.items():
        if "error" not in result:
            synthesis.append(f"## {topic}\n{result.get('summary', '')}")
        else:
            synthesis.append(f"## {topic}\né”™è¯¯: {result['error']}")

    final_synthesis = "\n\n".join(synthesis)

    return {
        **state,
        "current_step": "synthesize",
        "synthesis": final_synthesis,
        "messages": state["messages"] + ["ç»“æœç»¼åˆå®Œæˆ"]
    }

def perform_research(topic: str) -> Dict[str, Any]:
    """æ‰§è¡Œå•ä¸ªç ”ç©¶ä»»åŠ¡"""
    # æ¨¡æ‹Ÿç ”ç©¶è¿‡ç¨‹
    import time
    import random

    time.sleep(random.uniform(1, 3))  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

    return {
        "topic": topic,
        "summary": f"å…³äº'{topic}'çš„ç ”ç©¶æ€»ç»“",
        "key_findings": [f"å‘ç°{i}" for i in range(1, 4)],
        "confidence": random.uniform(0.7, 0.95)
    }
```

---

## âš¡ å·¥ä½œæµç¨‹

### 1. åŸºæœ¬æ‰§è¡Œæµç¨‹

```python
# åˆ›å»ºå·¥ä½œæµ
workflow = create_linear_workflow()

# å‡†å¤‡åˆå§‹çŠ¶æ€
initial_state = {
    "current_step": "start",
    "messages": [],
    "user_query": "åˆ†æäººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿",
    "research_topic": "äººå·¥æ™ºèƒ½å‘å±•",
    "session_id": "session_123"
}

# æ‰§è¡Œå·¥ä½œæµ
result = workflow.invoke(initial_state)

print("æ‰§è¡Œç»“æœ:")
print(f"æœ€ç»ˆæ­¥éª¤: {result['current_step']}")
print(f"æ¶ˆæ¯: {result['messages']}")
print(f"ç ”ç©¶æ•°æ®: {result.get('research_data', 'N/A')}")
```

### 2. æµå¼æ‰§è¡Œ

```python
def stream_execution(workflow, initial_state):
    """æµå¼æ‰§è¡Œå·¥ä½œæµ"""
    print("å¼€å§‹æµå¼æ‰§è¡Œ...")

    # è·å–ç”Ÿæˆå™¨
    generator = workflow.stream(initial_state)

    for step in generator:
        node_name = list(step.keys())[0]
        node_state = step[node_name]

        print(f"\n=== æ‰§è¡ŒèŠ‚ç‚¹: {node_name} ===")
        print(f"çŠ¶æ€: {node_state.get('current_step', 'unknown')}")
        print(f"æ¶ˆæ¯: {node_state.get('messages', [])}")

        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ è‡ªå®šä¹‰å¤„ç†é€»è¾‘
        if node_state.get("confidence", 0) < 0.5:
            print("âš ï¸  ç½®ä¿¡åº¦è¾ƒä½ï¼Œå¯èƒ½éœ€è¦äººå·¥å¹²é¢„")

    print("\n=== æ‰§è¡Œå®Œæˆ ===")

# ä½¿ç”¨æµå¼æ‰§è¡Œ
stream_execution(workflow, initial_state)
```

### 3. é”™è¯¯å¤„ç†å’Œæ¢å¤

```python
from functools import wraps

def with_error_handling(max_retries: int = 3):
    """é”™è¯¯å¤„ç†è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(state: WorkflowState, *args, **kwargs):
            error_count = state.get("error_count", 0)

            for attempt in range(max_retries):
                try:
                    return func(state, *args, **kwargs)
                except Exception as e:
                    error_count += 1
                    print(f"å°è¯• {attempt + 1} å¤±è´¥: {e}")

                    if attempt == max_retries - 1:
                        # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè¿›å…¥é”™è¯¯å¤„ç†æµç¨‹
                        return handle_critical_error(state, e)

                    # æ›´æ–°çŠ¶æ€å¹¶é‡è¯•
                    state = {
                        **state,
                        "error_count": error_count,
                        "last_error": str(e),
                        "retry_attempt": attempt + 1
                    }

            return state

        return wrapper
    return decorator

def handle_critical_error(state: WorkflowState, error: Exception) -> WorkflowState:
    """å¤„ç†å…³é”®é”™è¯¯"""
    return {
        **state,
        "current_step": "error",
        "error": str(error),
        "error_handled": False,
        "messages": state["messages"] + [
            f"é‡åˆ°å…³é”®é”™è¯¯: {error}",
            "éœ€è¦äººå·¥å¹²é¢„"
        ]
    }

@with_error_handling(max_retries=2)
def robust_research_node(state: WorkflowState) -> WorkflowState:
    """å¸¦é”™è¯¯å¤„ç†çš„ç¨³å¥ç ”ç©¶èŠ‚ç‚¹"""
    topic = state["research_topic"]

    # å¯èƒ½å¤±è´¥çš„æ“ä½œ
    research_data = perform_unreliable_research(topic)

    return {
        **state,
        "current_step": "research",
        "research_data": research_data,
        "messages": state["messages"] + ["ç ”ç©¶æˆåŠŸå®Œæˆ"]
    }

def perform_unreliable_research(topic: str) -> Dict[str, Any]:
    """æ¨¡æ‹Ÿå¯èƒ½å¤±è´¥çš„ç ”ç©¶æ“ä½œ"""
    import random

    if random.random() < 0.3:  # 30%å¤±è´¥ç‡
        raise ConnectionError("ç½‘ç»œè¿æ¥å¤±è´¥")

    return {
        "topic": topic,
        "findings": ["å‘ç°1", "å‘ç°2", "å‘ç°3"],
        "confidence": random.uniform(0.8, 0.95)
    }
```

### 4. æ¡ä»¶ä¸­æ–­å’Œæ¢å¤

```python
def create_interruptible_workflow():
    """åˆ›å»ºå¯ä¸­æ–­çš„å·¥ä½œæµ"""
    graph = StateGraph(WorkflowState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("process", process_node)
    graph.add_node("check_approval", check_approval_node)
    graph.add_node("human_review", human_review_node)
    graph.add_node("continue", continue_node)
    graph.add_node("finalize", finalize_node)

    # è®¾ç½®å…¥å£ç‚¹
    graph.set_entry_point("process")

    # æ·»åŠ è¾¹
    graph.add_edge("process", "check_approval")

    # æ¡ä»¶è¾¹ç”¨äºäººå·¥å¹²é¢„
    def route_for_approval(state: WorkflowState) -> str:
        requires_approval = state.get("requires_approval", False)
        confidence = state.get("confidence", 1.0)

        if requires_approval or confidence < 0.8:
            return "human_review"
        else:
            return "continue"

    graph.add_conditional_edges(
        "check_approval",
        route_for_approval,
        {
            "human_review": "human_review",
            "continue": "continue"
        }
    )

    # äººå·¥å®¡æŸ¥åå¯èƒ½ç»§ç»­æˆ–éœ€è¦è¿›ä¸€æ­¥ä¿®æ”¹
    graph.add_edge("human_review", "check_approval")
    graph.add_edge("continue", "finalize")
    graph.add_edge("finalize", END)

    return graph.compile()

def check_approval_node(state: WorkflowState) -> WorkflowState:
    """æ£€æŸ¥æ˜¯å¦éœ€è¦å®¡æ‰¹"""
    confidence = state.get("confidence", 0.0)
    requires_approval = confidence < 0.8

    return {
        **state,
        "current_step": "check_approval",
        "requires_approval": requires_approval,
        "messages": state["messages"] + [
            f"æ£€æŸ¥å®¡æ‰¹éœ€æ±‚: {'æ˜¯' if requires_approval else 'å¦'} (ç½®ä¿¡åº¦: {confidence:.2f})"
        ]
    }

def human_review_node(state: WorkflowState) -> WorkflowState:
    """äººå·¥å®¡æŸ¥èŠ‚ç‚¹"""
    print("ğŸ”´ éœ€è¦äººå·¥å¹²é¢„")
    print(f"å½“å‰çŠ¶æ€: {state}")

    # æ¨¡æ‹Ÿäººå·¥è¾“å…¥
    user_feedback = input("è¯·æä¾›å®¡æŸ¥æ„è§ (æˆ–è¾“å…¥ 'approve' æ‰¹å‡†): ")

    if user_feedback.lower() == "approve":
        approval_status = "approved"
        confidence = min(state.get("confidence", 0.0) + 0.2, 1.0)
    else:
        approval_status = "rejected"
        confidence = state.get("confidence", 0.0) - 0.1

    return {
        **state,
        "current_step": "human_review",
        "human_feedback": user_feedback,
        "approval_status": approval_status,
        "confidence": max(0.0, confidence),
        "messages": state["messages"] + [
            f"äººå·¥å®¡æŸ¥: {user_feedback}",
            f"å®¡æ‰¹çŠ¶æ€: {approval_status}"
        ]
    }
```

---

## ğŸ’¡ å®é™…åº”ç”¨ç¤ºä¾‹

### 1. ç ”ç©¶æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ

```python
def create_research_report_workflow():
    """åˆ›å»ºç ”ç©¶æŠ¥å‘Šç”Ÿæˆå·¥ä½œæµ"""
    graph = StateGraph(ResearchReportState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("plan", plan_research_node)
    graph.add_node("collect_data", collect_data_node)
    graph.add_node("analyze", analyze_data_node)
    graph.add_node("write_draft", write_draft_node)
    graph.add_node("peer_review", peer_review_node)
    graph.add_node("revise", revise_draft_node)
    graph.add_node("finalize", finalize_report_node)

    # è®¾ç½®å…¥å£ç‚¹
    graph.set_entry_point("plan")

    # æ¡ä»¶è¾¹
    def route_after_review(state: ResearchReportState) -> str:
        review_score = state.get("review_score", 0.0)

        if review_score >= 8.0:
            return "finalize"
        elif state.get("revision_count", 0) >= 3:
            return "finalize"  # æœ€å¤šä¿®è®¢3æ¬¡
        else:
            return "revise"

    # æ·»åŠ è¾¹
    graph.add_edge("plan", "collect_data")
    graph.add_edge("collect_data", "analyze")
    graph.add_edge("analyze", "write_draft")
    graph.add_edge("write_draft", "peer_review")
    graph.add_conditional_edges(
        "peer_review",
        route_after_review,
        {
            "revise": "revise",
            "finalize": "finalize"
        }
    )
    graph.add_edge("revise", "write_draft")  # ä¿®è®¢åé‡æ–°å†™ä½œ
    graph.add_edge("finalize", END)

    return graph.compile()

class ResearchReportState(TypedDict):
    current_step: str
    messages: Annotated[List[str], operator.add]

    # ç ”ç©¶ç›¸å…³
    research_topic: str
    research_plan: Optional[Dict[str, Any]]
    collected_data: List[Dict[str, Any]]
    analysis_results: Optional[Dict[str, Any]]

    # å†™ä½œç›¸å…³
    draft_content: Optional[str]
    review_score: Optional[float]
    revision_count: int

    # è´¨é‡æ§åˆ¶
    plagiarism_check_passed: bool
    fact_check_passed: bool
    quality_metrics: Dict[str, float]

def plan_research_node(state: ResearchReportState) -> ResearchReportState:
    """ç ”ç©¶è§„åˆ’èŠ‚ç‚¹"""
    topic = state["research_topic"]

    # åˆ›å»ºç ”ç©¶è®¡åˆ’
    research_plan = {
        "objectives": [
            f"åˆ†æ{topic}çš„ç°çŠ¶",
            f"è¯†åˆ«{topic}çš„å‘å±•è¶‹åŠ¿",
            f"è¯„ä¼°{topic}çš„å½±å“"
        ],
        "data_sources": ["å­¦æœ¯è®ºæ–‡", "æ–°é—»æŠ¥é“", "è¡Œä¸šæŠ¥å‘Š"],
        "methodology": "ç»¼åˆæ–‡çŒ®ç»¼è¿°å’Œæ•°æ®åˆ†æ",
        "timeline": "2å‘¨",
        "resources_needed": ["æœç´¢å·¥å…·", "åˆ†æè½¯ä»¶"]
    }

    return {
        **state,
        "current_step": "plan",
        "research_plan": research_plan,
        "messages": state["messages"] + [
            f"ç ”ç©¶è§„åˆ’å®Œæˆ: {topic}",
            "è§„åˆ’äº†4ä¸ªä¸»è¦ç›®æ ‡"
        ]
    }

def collect_data_node(state: ResearchReportState) -> ResearchReportState:
    """æ•°æ®æ”¶é›†èŠ‚ç‚¹"""
    research_plan = state["research_plan"]
    topic = state["research_topic"]

    # æ¨¡æ‹Ÿæ•°æ®æ”¶é›†
    collected_data = []

    for source in research_plan["data_sources"]:
        data = {
            "source": source,
            "items_collected": f"ä»{source}æ”¶é›†äº†20ç¯‡ç›¸å…³æ–‡ç« ",
            "key_insights": [
                f"å…³é”®æ´å¯Ÿ1æ¥è‡ª{source}",
                f"å…³é”®æ´å¯Ÿ2æ¥è‡ª{source}"
            ],
            "quality_score": 0.85,
            "relevance_score": 0.9
        }
        collected_data.append(data)

    return {
        **state,
        "current_step": "collect_data",
        "collected_data": collected_data,
        "messages": state["messages"] + [
            "æ•°æ®æ”¶é›†å®Œæˆ",
            f"ä»{len(collected_data)}ä¸ªæ•°æ®æºæ”¶é›†ä¿¡æ¯"
        ]
    }

def analyze_data_node(state: ResearchReportState) -> ResearchReportState:
    """æ•°æ®åˆ†æèŠ‚ç‚¹"""
    collected_data = state["collected_data"]

    # åˆ†ææ”¶é›†çš„æ•°æ®
    analysis_results = {
        "summary": "åŸºäºæ”¶é›†çš„æ•°æ®è¿›è¡Œåˆ†æ",
        "key_findings": [],
        "trends": [],
        "recommendations": [],
        "confidence_level": 0.88
    }

    # æå–å…³é”®å‘ç°
    for data in collected_data:
        analysis_results["key_findings"].extend(data["key_insights"])

    # è¯†åˆ«è¶‹åŠ¿
    analysis_results["trends"] = [
        "æŠ€æœ¯å¿«é€Ÿå‘å±•",
        "å¸‚åœºéœ€æ±‚å¢é•¿",
        "ç«äº‰åŠ å‰§"
    ]

    # ç”Ÿæˆå»ºè®®
    analysis_results["recommendations"] = [
        "ç»§ç»­æŠ•å…¥ç ”å‘",
        "å…³æ³¨å¸‚åœºå˜åŒ–",
        "åŠ å¼ºåˆä½œ"
    ]

    return {
        **state,
        "current_step": "analyze",
        "analysis_results": analysis_results,
        "messages": state["messages"] + [
            "æ•°æ®åˆ†æå®Œæˆ",
            f"è¯†åˆ«å‡º{len(analysis_results['key_findings'])}ä¸ªå…³é”®å‘ç°"
        ]
    }

def write_draft_node(state: ResearchReportState) -> ResearchReportState:
    """å†™ä½œè‰ç¨¿èŠ‚ç‚¹"""
    research_plan = state["research_plan"]
    collected_data = state["collected_data"]
    analysis_results = state["analysis_results"]

    # ç”ŸæˆæŠ¥å‘Šè‰ç¨¿
    draft_content = f"""
# {state['research_topic']}ç ”ç©¶æŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦
æœ¬æŠ¥å‘ŠåŸºäºå¯¹{state['research_topic']}çš„æ·±å…¥ç ”ç©¶ï¼Œåˆ†æäº†å½“å‰çŠ¶å†µå’Œå‘å±•è¶‹åŠ¿ã€‚

## ç ”ç©¶æ–¹æ³•
- æ•°æ®æ¥æº: {', '.join(research_plan['data_sources'])}
- ç ”ç©¶æ–¹æ³•: {research_plan['methodology']}
- æ•°æ®é‡: {len(collected_data)}ä¸ªæ•°æ®æº

## ä¸»è¦å‘ç°
{chr(10).join(f"- {finding}" for finding in analysis_results['key_findings'])}

## è¶‹åŠ¿åˆ†æ
{chr(10).join(f"- {trend}" for trend in analysis_results['trends'])}

## å»ºè®®
{chr(10).join(f"- {rec}" for rec in analysis_results['recommendations'])}

## ç»“è®º
æœ¬ç ”ç©¶æä¾›äº†å¯¹{state['research_topic']}çš„æ·±å…¥æ´å¯Ÿï¼Œå»ºè®®ç›¸å…³æ–¹é¢æ ¹æ®å‘ç°åˆ¶å®šç­–ç•¥ã€‚
"""

    return {
        **state,
        "current_step": "write_draft",
        "draft_content": draft_content,
        "messages": state["messages"] + [
            "æŠ¥å‘Šè‰ç¨¿å®Œæˆ",
            "åŒ…å«æ‰§è¡Œæ‘˜è¦ã€ä¸»è¦å‘ç°å’Œå»ºè®®"
        ]
    }

def peer_review_node(state: ResearchReportState) -> ResearchReportState:
    """åŒè¡Œè¯„å®¡èŠ‚ç‚¹"""
    draft_content = state["draft_content"]

    # æ¨¡æ‹ŸåŒè¡Œè¯„å®¡
    import random

    # è¯„åˆ†æ ‡å‡†ï¼šå†…å®¹è´¨é‡ã€é€»è¾‘æ€§ã€åˆ›æ–°æ€§ã€å¯è¯»æ€§
    quality_metrics = {
        "content_quality": random.uniform(7.0, 9.5),
        "logic": random.uniform(7.5, 9.0),
        "originality": random.uniform(6.5, 8.5),
        "readability": random.uniform(8.0, 9.5)
    }

    review_score = sum(quality_metrics.values()) / len(quality_metrics)

    # æ¨¡æ‹Ÿåé¦ˆ
    feedback = {
        "overall_score": review_score,
        "strengths": [
            "å†…å®¹ä¸°å¯Œï¼Œæ¶µç›–äº†ä¸»è¦æ–¹é¢",
            "ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘æ€§å¼º",
            "å»ºè®®å…·ä½“å¯æ“ä½œ"
        ],
        "weaknesses": [
            "å¯ä»¥å¢åŠ æ›´å¤šå…·ä½“æ•°æ®æ”¯æŒ",
            "æŸäº›ç»“è®ºéœ€è¦æ›´å¤šè®ºè¯",
            "å¯ä»¥è¡¥å……å›½é™…è§†é‡"
        ],
        "recommendations": [
            "æ·»åŠ æ›´å¤šå®šé‡åˆ†æ",
            "å¢å¼ºè®ºè¯é€»è¾‘",
            "å®Œå–„ç»“è®ºéƒ¨åˆ†"
        ]
    }

    return {
        **state,
        "current_step": "peer_review",
        "review_score": review_score,
        "quality_metrics": quality_metrics,
        "peer_feedback": feedback,
        "revision_count": state.get("revision_count", 0) + 1,
        "messages": state["messages"] + [
            f"åŒè¡Œè¯„å®¡å®Œæˆï¼Œè¯„åˆ†: {review_score:.1f}/10",
            f"æ”¶åˆ°{len(feedback['recommendations'])}æ¡æ”¹è¿›å»ºè®®"
        ]
    }

# ç¼–è¯‘å¹¶ä½¿ç”¨å·¥ä½œæµ
research_workflow = create_research_report_workflow()

# ç¤ºä¾‹æ‰§è¡Œ
initial_state = {
    "current_step": "start",
    "messages": [],
    "research_topic": "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨",
    "revision_count": 0
}

result = research_workflow.invoke(initial_state)
print("æœ€ç»ˆæŠ¥å‘Šè¯„åˆ†:", result.get("review_score", "N/A"))
```

### 2. å¤šAgentåä½œç³»ç»Ÿ

```python
def create_multi_agent_workflow():
    """åˆ›å»ºå¤šAgentåä½œå·¥ä½œæµ"""
    graph = StateGraph(MultiAgentState)

    # æ·»åŠ AgentèŠ‚ç‚¹
    graph.add_node("coordinator", coordinator_agent_node)
    graph.add_node("researcher", researcher_agent_node)
    graph.add_node("writer", writer_agent_node)
    graph.add_node("reviewer", reviewer_agent_node)
    graph.add_node("editor", editor_agent_node)

    # è®¾ç½®å…¥å£ç‚¹
    graph.set_entry_point("coordinator")

    # Agenté—´çš„åä½œæµç¨‹
    graph.add_edge("coordinator", "researcher")
    graph.add_edge("researcher", "writer")
    graph.add_edge("writer", "reviewer")

    # æ¡ä»¶è¾¹ï¼šå®¡ç¨¿å†³å®š
    def route_after_review(state: MultiAgentState) -> str:
        review_decision = state.get("review_decision", "revise")

        if review_decision == "approve":
            return "editor"
        elif review_decision == "revise":
            return "writer"
        else:
            return "coordinator"

    graph.add_conditional_edges(
        "reviewer",
        route_after_review,
        {
            "editor": "editor",
            "revise": "writer",
            "escalate": "coordinator"
        }
    )

    graph.add_edge("editor", END)

    return graph.compile()

class MultiAgentState(TypedDict):
    current_step: str
    messages: Annotated[List[str], operator.add]

    # ä»»åŠ¡ç›¸å…³
    task_description: str
    task_type: str
    priority: str

    # Agentç»“æœ
    research_results: Optional[Dict[str, Any]]
    draft_content: Optional[str]
    review_feedback: Optional[Dict[str, Any]]
    final_edit: Optional[str]

    # åä½œæ§åˆ¶
    assigned_agent: Optional[str]
    agent_status: Dict[str, str]
    coordination_decisions: List[str]

def coordinator_agent_node(state: MultiAgentState) -> MultiAgentState:
    """åè°ƒå‘˜AgentèŠ‚ç‚¹"""
    task_description = state["task_description"]

    # ä»»åŠ¡åˆ†æ
    task_analysis = analyze_task(task_description)

    # åˆ†é…ç»™åˆé€‚çš„Agent
    primary_agent = determine_primary_agent(task_analysis)

    coordination_decision = f"åˆ†é…ä»»åŠ¡ç»™{primary_agent}"

    return {
        **state,
        "current_step": "coordinator",
        "task_analysis": task_analysis,
        "assigned_agent": primary_agent,
        "coordination_decisions": state.get("coordination_decisions", []) + [coordination_decision],
        "agent_status": {
            **state.get("agent_status", {}),
            "coordinator": "completed"
        },
        "messages": state["messages"] + [
            f"åè°ƒå‘˜åˆ†æä»»åŠ¡: {task_description}",
            f"åˆ†é…ç»™{primary_agent}"
        ]
    }

def researcher_agent_node(state: MultiAgentState) -> MultiAgentState:
    """ç ”ç©¶å‘˜AgentèŠ‚ç‚¹"""
    task_analysis = state.get("task_analysis", {})
    task_description = state["task_description"]

    # æ¨¡æ‹Ÿç ”ç©¶è¿‡ç¨‹
    research_results = {
        "sources": [
            {"title": "ç›¸å…³è®ºæ–‡1", "relevance": 0.9},
            {"title": "ç›¸å…³è®ºæ–‡2", "relevance": 0.8},
            {"title": "è¡Œä¸šæŠ¥å‘Š", "relevance": 0.85}
        ],
        "key_findings": [
            "å‘ç°Aæ”¯æŒä¸»è¦è®ºç‚¹",
            "å‘ç°Bæä¾›è¡¥å……ä¿¡æ¯",
            "å‘ç°Cå±•ç¤ºåº”ç”¨æ¡ˆä¾‹"
        ],
        "data_quality": 0.88,
        "completeness": 0.92
    }

    return {
        **state,
        "current_step": "researcher",
        "research_results": research_results,
        "agent_status": {
            **state.get("agent_status", {}),
            "researcher": "completed"
        },
        "messages": state["messages"] + [
            "ç ”ç©¶å‘˜å®Œæˆä¿¡æ¯æ”¶é›†",
            f"æ”¶é›†åˆ°{len(research_results['sources'])}ä¸ªé«˜è´¨é‡èµ„æº"
        ]
    }

def writer_agent_node(state: MultiAgentState) -> MultiAgentState:
    """å†™ä½œAgentèŠ‚ç‚¹"""
    research_results = state.get("research_results", {})
    task_description = state["task_description"]

    # åŸºäºç ”ç©¶ç»“æœå†™ä½œ
    draft_content = f"""
ä»»åŠ¡ï¼š{task_description}

ç ”ç©¶æ€»ç»“ï¼š
åŸºäºæ”¶é›†çš„èµ„æ–™ï¼Œæˆ‘ä»¬å‘ç°ï¼š

ä¸»è¦å‘ç°ï¼š
{chr(10).join(f"- {finding}" for finding in research_results.get('key_findings', []))}

ç»“è®ºï¼š
æœ¬ç ”ç©¶ä¸ºç›¸å…³å†³ç­–æä¾›äº†æœ‰ä»·å€¼çš„å‚è€ƒã€‚
"""

    return {
        **state,
        "current_step": "writer",
        "draft_content": draft_content,
        "agent_status": {
            **state.get("agent_status", {}),
            "writer": "completed"
        },
        "messages": state["messages"] + [
            "å†™ä½œAgentå®Œæˆåˆç¨¿",
            "åŸºäºç ”ç©¶ç»“æœç”Ÿæˆäº†ç»“æ„åŒ–å†…å®¹"
        ]
    }

def reviewer_agent_node(state: MultiAgentState) -> MultiAgentState:
    """å®¡ç¨¿AgentèŠ‚ç‚¹"""
    draft_content = state.get("draft_content", "")

    # æ¨¡æ‹Ÿå®¡ç¨¿è¿‡ç¨‹
    import random

    review_criteria = {
        "accuracy": random.uniform(7.0, 9.5),
        "completeness": random.uniform(7.5, 9.0),
        "clarity": random.uniform(8.0, 9.5),
        "coherence": random.uniform(7.8, 9.2)
    }

    overall_score = sum(review_criteria.values()) / len(review_criteria)

    # å†³å®š
    if overall_score >= 8.5:
        review_decision = "approve"
    elif overall_score >= 7.0:
        review_decision = "revise"
    else:
        review_decision = "reject"

    review_feedback = {
        "scores": review_criteria,
        "overall_score": overall_score,
        "decision": review_decision,
        "comments": {
            "strengths": ["å†…å®¹å‡†ç¡®", "é€»è¾‘æ¸…æ™°"],
            "improvements": ["å¯ä»¥å¢åŠ æ›´å¤šç»†èŠ‚", "æŸäº›è¡¨è¿°å¯ä»¥ä¼˜åŒ–"]
        }
    }

    return {
        **state,
        "current_step": "reviewer",
        "review_feedback": review_feedback,
        "review_decision": review_decision,
        "agent_status": {
            **state.get("agent_status", {}),
            "reviewer": "completed"
        },
        "messages": state["messages"] + [
            f"å®¡ç¨¿å®Œæˆï¼Œè¯„åˆ†: {overall_score:.1f}/10",
            f"å†³å®š: {review_decision}"
        ]
    }

def editor_agent_node(state: MultiAgentState) -> MultiAgentState:
    """ç¼–è¾‘AgentèŠ‚ç‚¹"""
    draft_content = state.get("draft_content", "")
    review_feedback = state.get("review_feedback", {})

    # åŸºäºå®¡ç¨¿æ„è§è¿›è¡Œæœ€ç»ˆç¼–è¾‘
    final_edit = f"""
{state['task_description']}

--- ç¼–è¾‘ç‰ˆæœ¬ ---
{draft_content}

ç¼–è¾‘è¯´æ˜ï¼š
- æ ¹æ®å®¡ç¨¿æ„è§è¿›è¡Œäº†ä¼˜åŒ–
- æ”¹è¿›äº†è¡¨è¿°çš„å‡†ç¡®æ€§
- å¢å¼ºäº†é€»è¾‘è¿è´¯æ€§

è´¨é‡æ£€æŸ¥ï¼šé€šè¿‡ âœ…
"""

    return {
        **state,
        "current_step": "editor",
        "final_edit": final_edit,
        "agent_status": {
            **state.get("agent_status", {}),
            "editor": "completed"
        },
        "messages": state["messages"] + [
            "ç¼–è¾‘å®Œæˆ",
            "æœ€ç»ˆç‰ˆæœ¬å·²å‡†å¤‡å°±ç»ª"
        ]
    }

# ä½¿ç”¨ç¤ºä¾‹
multi_agent_workflow = create_multi_agent_workflow()

task_state = {
    "current_step": "start",
    "messages": [],
    "task_description": "ç¼–å†™ä¸€ä»½å…³äºåŒºå—é“¾æŠ€æœ¯å‘å±•è¶‹åŠ¿çš„åˆ†ææŠ¥å‘Š",
    "task_type": "research_report",
    "priority": "high",
    "agent_status": {}
}

result = multi_agent_workflow.invoke(task_state)
print("æœ€ç»ˆç»“æœ:")
print(result.get("final_edit", "N/A"))
```

### 3. å®¢æˆ·æœåŠ¡èŠå¤©æœºå™¨äºº

```python
def create_customer_service_workflow():
    """åˆ›å»ºå®¢æˆ·æœåŠ¡å·¥ä½œæµ"""
    graph = StateGraph(CustomerServiceState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("intention_detection", detect_intention_node)
    graph.add_node("knowledge_search", search_knowledge_node)
    graph.add_node("workflow_routing", route_workflow_node)
    graph.add_node("technical_support", technical_support_node)
    graph.add_node("billing_inquiry", billing_inquiry_node)
    graph.add_node("product_info", product_info_node)
    graph.add_node("human_handoff", human_handoff_node)
    graph.add_node("resolution_check", check_resolution_node)
    graph.add_node("follow_up", follow_up_node)

    # è®¾ç½®å…¥å£ç‚¹
    graph.set_entry_point("intention_detection")

    # æ„å›¾è·¯ç”±
    def route_by_intention(state: CustomerServiceState) -> str:
        intention = state.get("detected_intention", "general")

        intention_mapping = {
            "technical_issue": "technical_support",
            "billing": "billing_inquiry",
            "product_info": "product_info",
            "complaint": "human_handoff",
            "general": "knowledge_search"
        }

        return intention_mapping.get(intention, "knowledge_search")

    graph.add_conditional_edges(
        "intention_detection",
        route_by_intention,
        {
            "technical_support": "technical_support",
            "billing_inquiry": "billing_inquiry",
            "product_info": "product_info",
            "human_handoff": "human_handoff",
            "knowledge_search": "knowledge_search"
        }
    )

    # æ£€æŸ¥è§£å†³çŠ¶æ€
    def check_resolution(state: CustomerServiceState) -> str:
        resolved = state.get("issue_resolved", False)
        satisfaction = state.get("satisfaction_score", 0)

        if resolved and satisfaction >= 4:
            return "follow_up"
        elif resolved:
            return "end"
        else:
            return "human_handoff"

    # ä»å„ç§å¤„ç†èŠ‚ç‚¹åˆ°è§£å†³æ£€æŸ¥
    for node in ["technical_support", "billing_inquiry", "product_info", "knowledge_search"]:
        graph.add_edge(node, "resolution_check")

    graph.add_conditional_edges(
        "resolution_check",
        check_resolution,
        {
            "follow_up": "follow_up",
            "human_handoff": "human_handoff",
            "end": END
        }
    )

    graph.add_edge("human_handoff", "end")
    graph.add_edge("follow_up", END)

    return graph.compile()

class CustomerServiceState(TypedDict):
    current_step: str
    messages: Annotated[List[str], operator.add]

    # å®¢æˆ·ä¿¡æ¯
    customer_id: Optional[str]
    customer_tier: str

    # é—®é¢˜ç›¸å…³
    original_query: str
    detected_intention: Optional[str]
    confidence: float

    # å¤„ç†ç»“æœ
    search_results: Optional[List[Dict[str, Any]]]
    resolution: Optional[str]
    issue_resolved: bool
    satisfaction_score: Optional[float]

    # å‡çº§æ§åˆ¶
    escalation_count: int
    requires_human: bool

    # ä¸Šä¸‹æ–‡
    conversation_context: List[str]
    previous_resolutions: List[str]

def detect_intention_node(state: CustomerServiceState) -> CustomerServiceState:
    """æ„å›¾æ£€æµ‹èŠ‚ç‚¹"""
    query = state["original_query"]

    # æ„å›¾æ£€æµ‹é€»è¾‘
    intention_patterns = {
        "technical_issue": ["é”™è¯¯", "æ— æ³•", "æ•…éšœ", "é—®é¢˜", "bug"],
        "billing": ["è´¦å•", "æ”¶è´¹", "ä»·æ ¼", "é€€æ¬¾", "æ”¯ä»˜"],
        "product_info": ["åŠŸèƒ½", "ç‰¹æ€§", "å¦‚ä½•ä½¿ç”¨", "è§„æ ¼"],
        "complaint": ["æŠ•è¯‰", "ä¸æ»¡", "ç³Ÿç³•", "å¤±æœ›"],
        "general": ["ä½ å¥½", "å¸®åŠ©", "è¯·é—®"]
    }

    detected_intention = "general"
    max_matches = 0

    for intention, keywords in intention_patterns.items():
        matches = sum(1 for keyword in keywords if keyword in query)
        if matches > max_matches:
            max_matches = matches
            detected_intention = intention

    # è®¡ç®—ç½®ä¿¡åº¦
    confidence = min(max_matches * 0.3 + 0.5, 1.0)

    return {
        **state,
        "current_step": "intention_detection",
        "detected_intention": detected_intention,
        "confidence": confidence,
        "messages": state["messages"] + [
            f"æ£€æµ‹åˆ°æ„å›¾: {detected_intention} (ç½®ä¿¡åº¦: {confidence:.2f})"
        ]
    }

def search_knowledge_node(state: CustomerServiceState) -> CustomerServiceState:
    """çŸ¥è¯†åº“æœç´¢èŠ‚ç‚¹"""
    query = state["original_query"]
    intention = state["detected_intention"]

    # æ¨¡æ‹ŸçŸ¥è¯†åº“æœç´¢
    knowledge_base = {
        "technical_issue": [
            {"question": "åº”ç”¨æ— æ³•å¯åŠ¨", "answer": "è¯·å°è¯•é‡å¯åº”ç”¨æˆ–æ¸…é™¤ç¼“å­˜"},
            {"question": "ç™»å½•å¤±è´¥", "answer": "è¯·æ£€æŸ¥ç”¨æˆ·åå’Œå¯†ç æ˜¯å¦æ­£ç¡®"}
        ],
        "billing": [
            {"question": "å¦‚ä½•å–æ¶ˆè®¢é˜…", "answer": "å¯ä»¥åœ¨è´¦æˆ·è®¾ç½®ä¸­å–æ¶ˆè®¢é˜…"},
            {"question": "è´¦å•æŸ¥è¯¢", "answer": "è´¦å•ä¿¡æ¯å¯ä»¥åœ¨è´¦æˆ·é¡µé¢æŸ¥çœ‹"}
        ],
        "product_info": [
            {"question": "åŠŸèƒ½ä»‹ç»", "answer": "äº§å“å…·æœ‰ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½..."},
            {"question": "ä½¿ç”¨æ•™ç¨‹", "answer": "è¯¦ç»†ä½¿ç”¨æ•™ç¨‹è¯·æŸ¥çœ‹å¸®åŠ©æ–‡æ¡£"}
        ]
    }

    relevant_results = knowledge_base.get(intention, [])

    return {
        **state,
        "current_step": "knowledge_search",
        "search_results": relevant_results,
        "messages": state["messages"] + [
            f"æœç´¢åˆ°{len(relevant_results)}ä¸ªç›¸å…³ç»“æœ"
        ]
    }

def check_resolution_node(state: CustomerServiceState) -> CustomerServiceState:
    """è§£å†³çŠ¶æ€æ£€æŸ¥èŠ‚ç‚¹"""
    satisfaction = input(f"å®¢æˆ·æ»¡æ„åº¦è¯„åˆ† (1-5): ")

    try:
        satisfaction_score = float(satisfaction)
        issue_resolved = satisfaction_score >= 4
    except ValueError:
        satisfaction_score = 3.0
        issue_resolved = False

    return {
        **state,
        "current_step": "resolution_check",
        "satisfaction_score": satisfaction_score,
        "issue_resolved": issue_resolved,
        "messages": state["messages"] + [
            f"æ»¡æ„åº¦è¯„åˆ†: {satisfaction_score}",
            f"é—®é¢˜è§£å†³çŠ¶æ€: {'æ˜¯' if issue_resolved else 'å¦'}"
        ]
    }

def follow_up_node(state: CustomerServiceState) -> CustomerServiceState:
    """è·Ÿè¿›èŠ‚ç‚¹"""
    customer_id = state.get("customer_id", "æœªçŸ¥å®¢æˆ·")

    follow_up_message = f"""
æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼æˆ‘ä»¬ä¼šç»§ç»­æ”¹è¿›æœåŠ¡è´¨é‡ã€‚
å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ä»¬ã€‚

è·Ÿè¿›å®‰æ’ï¼š24å°æ—¶å†…ç”µè¯å›è®¿
è”ç³»äººï¼šå®¢æœä»£è¡¨ {state.get('assigned_agent', 'å®¢æœ')}
"""

    return {
        **state,
        "current_step": "follow_up",
        "follow_up_message": follow_up_message,
        "messages": state["messages"] + [
            "å·²å®‰æ’è·Ÿè¿›æœåŠ¡",
            "24å°æ—¶å†…ç”µè¯å›è®¿"
        ]
    }

# ä½¿ç”¨ç¤ºä¾‹
service_workflow = create_customer_service_workflow()

customer_state = {
    "current_step": "start",
    "messages": [],
    "customer_id": "CUST_12345",
    "customer_tier": "premium",
    "original_query": "æˆ‘çš„åº”ç”¨æ€»æ˜¯å´©æºƒï¼Œæ€ä¹ˆè§£å†³ï¼Ÿ",
    "escalation_count": 0,
    "conversation_context": []
}

result = service_workflow.invoke(customer_state)
print("æœåŠ¡ç»“æœ:", result.get("messages", []))
```

---

## ğŸš€ é«˜çº§ç‰¹æ€§

### 1. æ¡ä»¶æ‰§è¡Œå’ŒåŠ¨æ€è·¯ç”±

```python
from typing import Callable, Any

def create_advanced_routing_workflow():
    """åˆ›å»ºé«˜çº§è·¯ç”±å·¥ä½œæµ"""
    graph = StateGraph(AdvancedRoutingState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("analyze", analyze_request_node)
    graph.add_node("route", dynamic_router_node)
    graph.add_node("process_a", process_type_a_node)
    graph.add_node("process_b", process_type_b_node)
    graph.add_node("aggregate", aggregate_results_node)

    # è®¾ç½®å…¥å£ç‚¹
    graph.set_entry_point("analyze")

    # å¤æ‚çš„æ¡ä»¶è·¯ç”±
    def advanced_router(state: AdvancedRoutingState) -> str:
        """é«˜çº§è·¯ç”±å™¨"""
        request_type = state.get("request_type", "unknown")
        priority = state.get("priority", "normal")
        complexity = state.get("complexity_score", 0.5)
        available_resources = state.get("available_resources", [])

        # å¤æ‚çš„è·¯ç”±é€»è¾‘
        if request_type == "complex_analysis" and complexity > 0.8:
            return "process_b"
        elif request_type == "simple_query" and priority == "high":
            return "process_a"
        elif len(available_resources) < 2:
            return "process_a"  # èµ„æºä¸è¶³ï¼Œä½¿ç”¨ç®€å•å¤„ç†
        else:
            return "process_a"

    graph.add_conditional_edges(
        "route",
        advanced_router,
        {
            "process_a": "process_a",
            "process_b": "process_b"
        }
    )

    # æ±‡èšåˆ°èšåˆèŠ‚ç‚¹
    graph.add_edge("process_a", "aggregate")
    graph.add_edge("process_b", "aggregate")
    graph.add_edge("aggregate", END)

    return graph.compile()

class AdvancedRoutingState(TypedDict):
    current_step: str
    messages: Annotated[List[str], operator.add]

    # è¯·æ±‚ä¿¡æ¯
    request_type: str
    priority: str
    complexity_score: float
    available_resources: List[str]

    # å¤„ç†ç»“æœ
    processing_path: List[str]
    partial_results: Dict[str, Any]
    final_result: Optional[Any]

def dynamic_router_node(state: AdvancedRoutingState) -> AdvancedRoutingState:
    """åŠ¨æ€è·¯ç”±å™¨èŠ‚ç‚¹"""
    route_decision = f"åŸºäº{len(state.get('available_resources', []))}ä¸ªå¯ç”¨èµ„æºè¿›è¡Œè·¯ç”±"

    return {
        **state,
        "current_step": "route",
        "route_decision": route_decision,
        "processing_path": state.get("processing_path", []) + ["routed"],
        "messages": state["messages"] + [route_decision]
    }
```

### 2. å­å›¾å’Œå·¥ä½œæµåµŒå¥—

```python
def create_subgraph_workflow():
    """åˆ›å»ºåŒ…å«å­å›¾çš„å·¥ä½œæµ"""

    # åˆ›å»ºå­å›¾
    subgraph = StateGraph(SubgraphState)
    subgraph.add_node("sub_task_1", sub_task_1_node)
    subgraph.add_node("sub_task_2", sub_task_2_node)
    subgraph.add_edge("sub_task_1", "sub_task_2")
    subgraph.add_edge("sub_task_2", END)
    subgraph.set_entry_point("sub_task_1")

    # ç¼–è¯‘å­å›¾
    compiled_subgraph = subgraph.compile()

    # åˆ›å»ºä¸»å›¾
    graph = StateGraph(MainGraphState)
    graph.add_node("main_task", main_task_node)
    graph.add_node("subgraph", subgraph_node(compiled_subgraph))
    graph.add_node("post_process", post_process_node)

    graph.set_entry_point("main_task")
    graph.add_edge("main_task", "subgraph")
    graph.add_edge("subgraph", "post_process")
    graph.add_edge("post_process", END)

    return graph.compile()

def subgraph_node(subgraph):
    """åˆ›å»ºå­å›¾èŠ‚ç‚¹"""
    def wrapper(state: MainGraphState) -> MainGraphState:
        # å‡†å¤‡å­å›¾è¾“å…¥
        subgraph_input = {
            "sub_tasks": state.get("sub_tasks", []),
            "sub_messages": []
        }

        # æ‰§è¡Œå­å›¾
        subgraph_result = subgraph.invoke(subgraph_input)

        # å¤„ç†å­å›¾ç»“æœ
        return {
            **state,
            "current_step": "subgraph",
            "subgraph_result": subgraph_result,
            "messages": state["messages"] + ["å­å›¾æ‰§è¡Œå®Œæˆ"]
        }

    return wrapper
```

### 3. äº‹ä»¶é©±åŠ¨å’Œç›‘å¬å™¨

```python
from typing import Dict, Callable, List
import asyncio

class EventSystem:
    """äº‹ä»¶ç³»ç»Ÿ"""

    def __init__(self):
        self.listeners: Dict[str, List[Callable]] = {}

    def on(self, event: str, callback: Callable):
        """æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨"""
        if event not in self.listeners:
            self.listeners[event] = []
        self.listeners[event].append(callback)

    async def emit(self, event: str, data: Any):
        """è§¦å‘äº‹ä»¶"""
        if event in self.listeners:
            for callback in self.listeners[event]:
                await callback(data)

# å…¨å±€äº‹ä»¶ç³»ç»Ÿ
event_system = EventSystem()

def create_event_driven_workflow():
    """åˆ›å»ºäº‹ä»¶é©±åŠ¨å·¥ä½œæµ"""
    graph = StateGraph(EventDrivenState)

    # æ·»åŠ äº‹ä»¶ç›‘å¬å™¨
    @event_system.on("high_confidence")
    async def handle_high_confidence(data):
        print(f"ğŸ‰ é«˜ç½®ä¿¡åº¦ç»“æœ: {data}")

    @event_system.on("error_occurred")
    async def handle_error(data):
        print(f"âš ï¸  å‘ç”Ÿé”™è¯¯: {data}")

    graph.add_node("process", event_driven_process_node)
    graph.add_node("validate", validation_node)
    graph.add_node("handle_error", error_handler_node)

    graph.set_entry_point("process")
    graph.add_edge("process", "validate")
    graph.add_edge("validate", END)

    return graph.compile()

async def event_driven_process_node(state: EventDrivenState) -> EventDrivenState:
    """äº‹ä»¶é©±åŠ¨å¤„ç†èŠ‚ç‚¹"""
    confidence = state.get("confidence", 0.5)

    # æ¨¡æ‹Ÿå¤„ç†
    if confidence > 0.8:
        await event_system.emit("high_confidence", {"confidence": confidence})
    elif confidence < 0.3:
        await event_system.emit("low_confidence", {"confidence": confidence})

    return {
        **state,
        "current_step": "process",
        "messages": state["messages"] + [f"å¤„ç†å®Œæˆï¼Œç½®ä¿¡åº¦: {confidence}"]
    }

class EventDrivenState(TypedDict):
    current_step: str
    messages: Annotated[List[str], operator.add]
    confidence: float
    event_history: List[Dict[str, Any]]
```

### 4. ç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–

```python
import hashlib
import json
from functools import wraps

class ResultCache:
    """ç»“æœç¼“å­˜"""

    def __init__(self, max_size: int = 1000):
        self.cache: Dict[str, Any] = {}
        self.access_order: List[str] = []
        self.max_size = max_size

    def _get_cache_key(self, state: Dict[str, Any], node_name: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # ç§»é™¤å¯å˜å­—æ®µ
        cacheable_state = {
            k: v for k, v in state.items()
            if k not in ["messages", "current_step", "step_count"]
        }

        key_data = {
            "node": node_name,
            "state": cacheable_state
        }

        return hashlib.md5(json.dumps(key_data, sort_keys=True).encode()).hexdigest()

    def get(self, state: Dict[str, Any], node_name: str) -> Any:
        """è·å–ç¼“å­˜"""
        cache_key = self._get_cache_key(state, node_name)

        if cache_key in self.cache:
            # æ›´æ–°è®¿é—®é¡ºåº
            if cache_key in self.access_order:
                self.access_order.remove(cache_key)
            self.access_order.append(cache_key)

            return self.cache[cache_key]

        return None

    def set(self, state: Dict[str, Any], node_name: str, result: Any):
        """è®¾ç½®ç¼“å­˜"""
        cache_key = self._get_cache_key(state, node_name)

        # æ£€æŸ¥ç¼“å­˜å¤§å°
        if len(self.cache) >= self.max_size:
            # ç§»é™¤æœ€æ—§çš„æ¡ç›®
            oldest_key = self.access_order.pop(0)
            del self.cache[oldest_key]

        self.cache[cache_key] = result
        self.access_order.append(cache_key)

    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        self.access_order.clear()

# å…¨å±€ç¼“å­˜å®ä¾‹
result_cache = ResultCache()

def with_caching(ttl: int = 3600):
    """ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(state: Dict[str, Any], *args, **kwargs):
            node_name = func.__name__

            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = result_cache.get(state, node_name)
            if cached_result is not None:
                return cached_result

            # æ‰§è¡Œå‡½æ•°
            result = func(state, *args, **kwargs)

            # ç¼“å­˜ç»“æœ
            result_cache.set(state, node_name, result)

            return result

        return wrapper
    return decorator

@with_caching()
def cached_research_node(state: WorkflowState) -> WorkflowState:
    """å¸¦ç¼“å­˜çš„ç ”ç©¶èŠ‚ç‚¹"""
    # è€—æ—¶çš„ç ”ç©¶æ“ä½œ
    topic = state["research_topic"]
    result = perform_expensive_research(topic)

    return {
        **state,
        "current_step": "research",
        "research_data": result,
        "messages": state["messages"] + ["ç ”ç©¶å®Œæˆï¼ˆä»ç¼“å­˜æˆ–é‡æ–°è®¡ç®—ï¼‰"]
    }
```

### 5. ç›‘æ§å’Œå¯è§‚å¯Ÿæ€§

```python
import time
from datetime import datetime
from typing import Dict, Any, List

class WorkflowMonitor:
    """å·¥ä½œæµç›‘æ§"""

    def __init__(self):
        self.executions: List[Dict[str, Any]] = []
        self.node_performance: Dict[str, List[float]] = {}
        self.error_counts: Dict[str, int] = {}

    def start_execution(self, workflow_id: str, initial_state: Dict[str, Any]):
        """å¼€å§‹æ‰§è¡Œç›‘æ§"""
        self.current_execution = {
            "workflow_id": workflow_id,
            "start_time": datetime.now().isoformat(),
            "initial_state": initial_state,
            "node_executions": [],
            "errors": []
        }

    def record_node_execution(self, node_name: str, start_time: float, end_time: float, result: Any):
        """è®°å½•èŠ‚ç‚¹æ‰§è¡Œ"""
        execution_time = end_time - start_time

        # è®°å½•èŠ‚ç‚¹æ€§èƒ½
        if node_name not in self.node_performance:
            self.node_performance[node_name] = []
        self.node_performance[node_name].append(execution_time)

        # è®°å½•å½“å‰æ‰§è¡Œ
        node_execution = {
            "node_name": node_name,
            "start_time": start_time,
            "end_time": end_time,
            "execution_time": execution_time,
            "result_summary": str(result)[:100]  # åªä¿å­˜ç»“æœæ‘˜è¦
        }

        self.current_execution["node_executions"].append(node_execution)

    def record_error(self, node_name: str, error: Exception):
        """è®°å½•é”™è¯¯"""
        self.error_counts[node_name] = self.error_counts.get(node_name, 0) + 1

        error_record = {
            "node_name": node_name,
            "error_type": type(error).__name__,
            "error_message": str(error),
            "timestamp": datetime.now().isoformat()
        }

        self.current_execution["errors"].append(error_record)

    def end_execution(self, final_state: Dict[str, Any]):
        """ç»“æŸæ‰§è¡Œç›‘æ§"""
        self.current_execution["end_time"] = datetime.now().isoformat()
        self.current_execution["final_state"] = final_state
        self.current_execution["total_execution_time"] = (
            datetime.fromisoformat(self.current_execution["end_time"]) -
            datetime.fromisoformat(self.current_execution["start_time"])
        ).total_seconds()

        self.executions.append(self.current_execution.copy())

    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        report = {
            "total_executions": len(self.executions),
            "average_execution_time": 0,
            "node_performance": {},
            "error_statistics": self.error_counts
        }

        if self.executions:
            # è®¡ç®—å¹³å‡æ‰§è¡Œæ—¶é—´
            total_time = sum(exec["total_execution_time"] for exec in self.executions)
            report["average_execution_time"] = total_time / len(self.executions)

        # èŠ‚ç‚¹æ€§èƒ½ç»Ÿè®¡
        for node, times in self.node_performance.items():
            if times:
                report["node_performance"][node] = {
                    "average_time": sum(times) / len(times),
                    "min_time": min(times),
                    "max_time": max(times),
                    "execution_count": len(times)
                }

        return report

# å…¨å±€ç›‘æ§å®ä¾‹
monitor = WorkflowMonitor()

def with_monitoring(func):
    """ç›‘æ§è£…é¥°å™¨"""
    def wrapper(state: Dict[str, Any], *args, **kwargs):
        node_name = func.__name__
        start_time = time.time()

        try:
            result = func(state, *args, **kwargs)
            end_time = time.time()

            # è®°å½•æˆåŠŸçš„æ‰§è¡Œ
            monitor.record_node_execution(node_name, start_time, end_time, result)

            return result

        except Exception as e:
            end_time = time.time()

            # è®°å½•é”™è¯¯
            monitor.record_error(node_name, e)
            raise

        finally:
            # ç¡®ä¿çŠ¶æ€æ›´æ–°
            pass

    return wrapper

@with_monitoring()
def monitored_research_node(state: WorkflowState) -> WorkflowState:
    """å¸¦ç›‘æ§çš„ç ”ç©¶èŠ‚ç‚¹"""
    # æ‰§è¡Œç ”ç©¶æ“ä½œ
    topic = state["research_topic"]
    result = perform_research(topic)

    return {
        **state,
        "current_step": "research",
        "research_data": result,
        "messages": state["messages"] + ["ç ”ç©¶å®Œæˆ"]
    }

def create_monitored_workflow():
    """åˆ›å»ºå¸¦ç›‘æ§çš„å·¥ä½œæµ"""
    graph = StateGraph(WorkflowState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("start", start_node)
    graph.add_node("research", monitored_research_node)
    graph.add_node("analyze", monitored_analyze_node)
    graph.add_node("finalize", finalize_node)

    graph.set_entry_point("start")
    graph.add_edge("start", "research")
    graph.add_edge("research", "analyze")
    graph.add_edge("analyze", "finalize")
    graph.add_edge("finalize", END)

    return graph.compile()

@with_monitoring()
def monitored_analyze_node(state: WorkflowState) -> WorkflowState:
    """å¸¦ç›‘æ§çš„åˆ†æèŠ‚ç‚¹"""
    research_data = state.get("research_data", {})

    # æ‰§è¡Œåˆ†æ
    analysis = analyze_data(research_data)

    return {
        **state,
        "current_step": "analyze",
        "analysis": analysis,
        "messages": state["messages"] + ["åˆ†æå®Œæˆ"]
    }

# ä½¿ç”¨ç¤ºä¾‹
def run_monitored_workflow():
    """è¿è¡Œå¸¦ç›‘æ§çš„å·¥ä½œæµ"""
    workflow = create_monitored_workflow()

    # å¼€å§‹ç›‘æ§
    monitor.start_execution("research_workflow_1", {"topic": "AIå‘å±•"})

    initial_state = {
        "current_step": "start",
        "messages": [],
        "research_topic": "AIå‘å±•",
        "step_count": 0
    }

    try:
        result = workflow.invoke(initial_state)
        monitor.end_execution(result)

        # è·å–æ€§èƒ½æŠ¥å‘Š
        performance_report = monitor.get_performance_report()
        print("æ€§èƒ½æŠ¥å‘Š:", performance_report)

    except Exception as e:
        monitor.end_execution({"error": str(e)})
        print(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
```

---

## âœ… æœ€ä½³å®è·µ

### 1. çŠ¶æ€è®¾è®¡æœ€ä½³å®è·µ

#### A. çŠ¶æ€ç»“æ„è®¾è®¡

```python
# âœ… å¥½çš„çŠ¶æ€è®¾è®¡
class WellDesignedState(TypedDict):
    # å¿…éœ€çš„å…ƒæ•°æ®
    current_step: str
    session_id: str
    step_count: int

    # ä¸šåŠ¡æ•°æ®ï¼ˆåˆ†å±‚ç»„ç»‡ï¼‰
    user_input: str
    processing_results: Dict[str, Any]

    # æ§åˆ¶æµçŠ¶æ€
    confidence: float
    requires_review: bool
    retry_count: int

    # ä¸Šä¸‹æ–‡ä¿¡æ¯
    metadata: Dict[str, Any]
    error_log: List[str]

# âŒ é¿å…çš„çŠ¶æ€è®¾è®¡
class PoorlyDesignedState(TypedDict):
    # æ··åˆäº†å¤ªå¤šä¸ç›¸å…³çš„å­—æ®µ
    random_data: Any
    temp_variables: List[Any]
    debug_info: Dict[str, Any]
    # ç¼ºä¹æ˜ç¡®çš„è¯­ä¹‰
```

#### B. çŠ¶æ€æ›´æ–°ç­–ç•¥

```python
def safe_state_update(state: Dict[str, Any], updates: Dict[str, Any]) -> Dict[str, Any]:
    """å®‰å…¨çš„çŠ¶æ€æ›´æ–°"""
    # éªŒè¯æ›´æ–°
    validated_updates = validate_state_updates(updates)

    # åŸå­æ›´æ–°
    new_state = {**state, **validated_updates}

    # æ·»åŠ å®¡è®¡ä¿¡æ¯
    new_state["last_updated"] = datetime.now().isoformat()
    new_state["step_count"] = state.get("step_count", 0) + 1

    return new_state

def validate_state_updates(updates: Dict[str, Any]) -> Dict[str, Any]:
    """éªŒè¯çŠ¶æ€æ›´æ–°"""
    validated = {}

    for key, value in updates.items():
        # åŸºæœ¬éªŒè¯
        if value is None:
            continue

        # ç±»å‹æ£€æŸ¥
        if key == "confidence" and not isinstance(value, (int, float)):
            raise ValueError("confidenceå¿…é¡»æ˜¯æ•°å­—")
        elif key == "messages" and not isinstance(value, list):
            raise ValueError("messageså¿…é¡»æ˜¯åˆ—è¡¨")
        elif key == "metadata" and not isinstance(value, dict):
            raise ValueError("metadataå¿…é¡»æ˜¯å­—å…¸")

        validated[key] = value

    return validated
```

### 2. èŠ‚ç‚¹è®¾è®¡æœ€ä½³å®è·µ

#### A. å•ä¸€èŒè´£åŸåˆ™

```python
# âœ… å¥½çš„èŠ‚ç‚¹è®¾è®¡ï¼šå•ä¸€èŒè´£
def validate_input_node(state: WorkflowState) -> WorkflowState:
    """ä»…è´Ÿè´£è¾“å…¥éªŒè¯"""
    user_input = state["user_input"]

    if not user_input or len(user_input.strip()) < 3:
        return {
            **state,
            "current_step": "validation",
            "is_valid": False,
            "validation_errors": ["è¾“å…¥å¤ªçŸ­"],
            "messages": state["messages"] + ["è¾“å…¥éªŒè¯å¤±è´¥"]
        }

    return {
        **state,
        "current_step": "validation",
        "is_valid": True,
        "messages": state["messages"] + ["è¾“å…¥éªŒè¯é€šè¿‡"]
    }

# âŒ é¿å…ï¼šèŒè´£è¿‡å¤šçš„èŠ‚ç‚¹
def over_loaded_node(state: WorkflowState) -> WorkflowState:
    """è¿™ä¸ªèŠ‚ç‚¹åšäº†å¤ªå¤šäº‹æƒ…"""
    # è¾“å…¥éªŒè¯
    # æ•°æ®å¤„ç†
    # ä¸šåŠ¡é€»è¾‘
    # ç»“æœç”Ÿæˆ
    # çŠ¶æ€æ›´æ–°
    # é”™è¯¯å¤„ç†
    # æ—¥å¿—è®°å½•
    # é€šçŸ¥å‘é€
    # ...
    pass
```

#### B. é”™è¯¯å¤„ç†

```python
def resilient_node(state: WorkflowState) -> WorkflowState:
    """å…·æœ‰é”™è¯¯å¤„ç†èƒ½åŠ›çš„èŠ‚ç‚¹"""
    try:
        # æ‰§è¡Œä¸»è¦é€»è¾‘
        result = perform_operation(state["data"])

        return {
            **state,
            "current_step": "processing",
            "result": result,
            "messages": state["messages"] + ["å¤„ç†æˆåŠŸ"]
        }

    except ValidationError as e:
        # è¾“å…¥éªŒè¯é”™è¯¯
        return {
            **state,
            "current_step": "error",
            "error_type": "validation",
            "error_message": str(e),
            "retry_count": state.get("retry_count", 0) + 1,
            "messages": state["messages"] + [f"éªŒè¯é”™è¯¯: {e}"]
        }

    except TimeoutError:
        # è¶…æ—¶é”™è¯¯
        return {
            **state,
            "current_step": "timeout",
            "retry_count": state.get("retry_count", 0) + 1,
            "messages": state["messages"] + ["å¤„ç†è¶…æ—¶"]
        }

    except Exception as e:
        # æœªçŸ¥é”™è¯¯
        return {
            **state,
            "current_step": "error",
            "error_type": "unknown",
            "error_message": str(e),
            "needs_manual_review": True,
            "messages": state["messages"] + [f"å¤„ç†é”™è¯¯: {e}"]
        }
```

### 3. æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ

#### A. é¿å…ä¸å¿…è¦çš„è®¡ç®—

```python
from functools import lru_cache

@lru_cache(maxsize=128)
def expensive_computation(task_id: str, parameters: tuple) -> Dict[str, Any]:
    """å¸¦ç¼“å­˜çš„æ˜‚è´µè®¡ç®—"""
    # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
    time.sleep(2)
    return {"result": f"è®¡ç®—ç»“æœ for {task_id}"}

def optimized_node(state: WorkflowState) -> WorkflowState:
    """ä¼˜åŒ–çš„èŠ‚ç‚¹"""
    task_id = state["task_id"]
    parameters = tuple(sorted(state.get("parameters", {}).items()))

    # ä½¿ç”¨ç¼“å­˜é¿å…é‡å¤è®¡ç®—
    if task_id in state.get("cached_results", {}):
        cached_result = state["cached_results"][task_id]
    else:
        cached_result = expensive_computation(task_id, parameters)

        # æ›´æ–°ç¼“å­˜
        cached_results = state.get("cached_results", {})
        cached_results[task_id] = cached_result

        return {
            **state,
            "current_step": "processing",
            "result": cached_result,
            "cached_results": cached_results,
            "messages": state["messages"] + ["ä½¿ç”¨ç¼“å­˜ç»“æœ" if task_id in state.get("cached_results", {}) else "è®¡ç®—æ–°ç»“æœ"]
        }
```

#### B. å¹¶è¡Œå¤„ç†

```python
from concurrent.futures import ThreadPoolExecutor, as_completed

def parallel_processing_node(state: WorkflowState) -> WorkflowState:
    """å¹¶è¡Œå¤„ç†èŠ‚ç‚¹"""
    tasks = state.get("parallel_tasks", [])

    if not tasks:
        return {
            **state,
            "current_step": "parallel_processing",
            "results": {},
            "messages": state["messages"] + ["æ²¡æœ‰å¹¶è¡Œä»»åŠ¡"]
        }

    results = {}

    with ThreadPoolExecutor(max_workers=min(len(tasks), 4)) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_task = {
            executor.submit(process_individual_task, task): task
            for task in tasks
        }

        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_task):
            task = future_to_task[future]
            try:
                result = future.result()
                results[task["id"]] = result
            except Exception as e:
                results[task["id"]] = {"error": str(e)}

    return {
        **state,
        "current_step": "parallel_processing",
        "results": results,
        "messages": state["messages"] + [
            f"å¹¶è¡Œå¤„ç†å®Œæˆï¼Œå¤„ç†äº†{len(tasks)}ä¸ªä»»åŠ¡"
        ]
    }
```

### 4. å¯æµ‹è¯•æ€§æœ€ä½³å®è·µ

#### A. å•å…ƒæµ‹è¯•

```python
import pytest
from unittest.mock import Mock, patch

def test_research_node():
    """æµ‹è¯•ç ”ç©¶èŠ‚ç‚¹"""
    # å‡†å¤‡æµ‹è¯•çŠ¶æ€
    test_state = {
        "current_step": "start",
        "messages": [],
        "research_topic": "äººå·¥æ™ºèƒ½",
        "step_count": 0
    }

    # æ¨¡æ‹Ÿå¤–éƒ¨ä¾èµ–
    with patch('your_module.perform_research') as mock_research:
        mock_research.return_value = {
            "findings": ["å‘ç°1", "å‘ç°2"],
            "confidence": 0.9
        }

        # æ‰§è¡ŒèŠ‚ç‚¹
        result = research_node(test_state)

        # éªŒè¯ç»“æœ
        assert result["current_step"] == "research"
        assert "research_data" in result
        assert len(result["research_data"]["findings"]) == 2
        assert mock_research.called
        assert mock_research.call_args[0][0] == "äººå·¥æ™ºèƒ½"

def test_state_validation():
    """æµ‹è¯•çŠ¶æ€éªŒè¯"""
    valid_updates = {
        "confidence": 0.8,
        "messages": ["æµ‹è¯•æ¶ˆæ¯"],
        "metadata": {"key": "value"}
    }

    invalid_updates = {
        "confidence": "invalid",  # ç±»å‹é”™è¯¯
        "messages": "not_a_list"  # ç±»å‹é”™è¯¯
    }

    # éªŒè¯æœ‰æ•ˆæ›´æ–°
    validated = validate_state_updates(valid_updates)
    assert validated == valid_updates

    # éªŒè¯æ— æ•ˆæ›´æ–°ï¼ˆåº”è¯¥æŠ›å‡ºå¼‚å¸¸ï¼‰
    with pytest.raises(ValueError):
        validate_state_updates(invalid_updates)
```

#### B. é›†æˆæµ‹è¯•

```python
def test_workflow_integration():
    """æµ‹è¯•å·¥ä½œæµé›†æˆ"""
    workflow = create_research_workflow()

    initial_state = {
        "current_step": "start",
        "messages": [],
        "research_topic": "æœºå™¨å­¦ä¹ ",
        "step_count": 0
    }

    # æ‰§è¡Œå·¥ä½œæµ
    result = workflow.invoke(initial_state)

    # éªŒè¯å®Œæ•´æµç¨‹
    assert result["current_step"] == "end"
    assert "research_data" in result
    assert "analysis" in result
    assert len(result["messages"]) > 0

    # éªŒè¯æ¶ˆæ¯é¡ºåº
    expected_messages = ["å·¥ä½œæµå¼€å§‹", "ç ”ç©¶å®Œæˆ", "åˆ†æå®Œæˆ"]
    for expected_msg in expected_messages:
        assert any(expected_msg in msg for msg in result["messages"])

def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    workflow = create_robust_workflow()

    # æµ‹è¯•é”™è¯¯çŠ¶æ€
    error_state = {
        "current_step": "start",
        "messages": [],
        "error": "æ¨¡æ‹Ÿé”™è¯¯",
        "retry_count": 0
    }

    result = workflow.invoke(error_state)

    # éªŒè¯é”™è¯¯å¤„ç†
    assert result["current_step"] == "error_handled"
    assert "error_logged" in result
```

### 5. æ–‡æ¡£å’Œæ³¨é‡Šæœ€ä½³å®è·µ

```python
def complex_business_logic_node(state: ComplexWorkflowState) -> ComplexWorkflowState:
    """
    æ‰§è¡Œå¤æ‚çš„ä¸šåŠ¡é€»è¾‘å¤„ç†

    è¯¥èŠ‚ç‚¹è´Ÿè´£ï¼š
    1. éªŒè¯è¾“å…¥æ•°æ®çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§
    2. æ ¹æ®ä¸šåŠ¡è§„åˆ™è¿›è¡Œæ•°æ®è½¬æ¢
    3. è°ƒç”¨å¤–éƒ¨APIè·å–è¡¥å……ä¿¡æ¯
    4. ç”Ÿæˆä¸šåŠ¡å†³ç­–å»ºè®®

    Args:
        state (ComplexWorkflowState): å½“å‰å·¥ä½œæµçŠ¶æ€ï¼Œå¿…é¡»åŒ…å«ï¼š
            - user_input: ç”¨æˆ·è¾“å…¥æ•°æ®
            - business_context: ä¸šåŠ¡ä¸Šä¸‹æ–‡ä¿¡æ¯
            - validation_rules: éªŒè¯è§„åˆ™é…ç½®

    Returns:
        ComplexWorkflowState: æ›´æ–°åçš„çŠ¶æ€ï¼ŒåŒ…å«ï¼š
            - processing_result: å¤„ç†ç»“æœ
            - business_decision: ä¸šåŠ¡å†³ç­–
            - confidence_score: ç½®ä¿¡åº¦è¯„åˆ†
            - validation_report: éªŒè¯æŠ¥å‘Š

    Raises:
        ValidationError: å½“è¾“å…¥æ•°æ®éªŒè¯å¤±è´¥æ—¶
        BusinessRuleError: å½“ä¸šåŠ¡è§„åˆ™æ£€æŸ¥å¤±è´¥æ—¶
        ExternalAPIError: å½“å¤–éƒ¨APIè°ƒç”¨å¤±è´¥æ—¶

    Example:
        >>> state = {"user_input": "purchase_request", "business_context": {...}}
        >>> result = complex_business_logic_node(state)
        >>> print(result["business_decision"])
        "approved_with_conditions"
    """
    # å®ç°é€»è¾‘...
    pass

# çŠ¶æ€ç±»æ–‡æ¡£
class ComplexWorkflowState(TypedDict):
    """
    å¤æ‚å·¥ä½œæµçŠ¶æ€å®šä¹‰

    Attributes:
        current_step (str): å½“å‰æ‰§è¡Œæ­¥éª¤
        user_input (Dict[str, Any]): ç”¨æˆ·è¾“å…¥æ•°æ®
        business_context (Dict[str, Any]): ä¸šåŠ¡ä¸Šä¸‹æ–‡ä¿¡æ¯
        validation_rules (Dict[str, Any]): éªŒè¯è§„åˆ™é…ç½®
        processing_result (Optional[Dict[str, Any]]): å¤„ç†ç»“æœ
        business_decision (Optional[str]): ä¸šåŠ¡å†³ç­–
        confidence_score (Optional[float]): ç½®ä¿¡åº¦è¯„åˆ† (0.0-1.0)
        validation_report (Optional[Dict[str, Any]]): éªŒè¯æŠ¥å‘Š
        error_log (List[str]): é”™è¯¯æ—¥å¿—
        retry_count (int): é‡è¯•æ¬¡æ•°
    """

    current_step: str
    user_input: Dict[str, Any]
    business_context: Dict[str, Any]
    validation_rules: Dict[str, Any]

    # å¯é€‰å­—æ®µ
    processing_result: Optional[Dict[str, Any]]
    business_decision: Optional[str]
    confidence_score: Optional[float]
    validation_report: Optional[Dict[str, Any]]
    error_log: List[str]
    retry_count: int
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•è°ƒè¯•LangGraphå·¥ä½œæµï¼Ÿ

```python
import logging
from typing import Any, Dict

# è®¾ç½®è°ƒè¯•æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

def debug_node(state: WorkflowState) -> WorkflowState:
    """å¸¦è°ƒè¯•ä¿¡æ¯çš„èŠ‚ç‚¹"""
    logger.debug(f"è¿›å…¥èŠ‚ç‚¹ï¼Œå½“å‰çŠ¶æ€: {state}")

    try:
        result = process_data(state["data"])
        logger.info(f"èŠ‚ç‚¹å¤„ç†æˆåŠŸï¼Œç»“æœ: {result}")

        return {
            **state,
            "current_step": "processed",
            "processed_data": result,
            "messages": state["messages"] + ["å¤„ç†æˆåŠŸ"]
        }

    except Exception as e:
        logger.error(f"èŠ‚ç‚¹å¤„ç†å¤±è´¥: {e}")
        logger.debug(f"å¤±è´¥æ—¶çš„çŠ¶æ€: {state}")

        return {
            **state,
            "current_step": "error",
            "error": str(e),
            "messages": state["messages"] + [f"é”™è¯¯: {e}"]
        }

# çŠ¶æ€è¿½è¸ªè£…é¥°å™¨
def trace_state_changes(func):
    """è¿½è¸ªçŠ¶æ€å˜åŒ–çš„è£…é¥°å™¨"""
    def wrapper(state: Dict[str, Any], *args, **kwargs):
        initial_state = state.copy()
        logger.debug(f"æ‰§è¡Œ {func.__name__} å‰çŠ¶æ€: {initial_state}")

        result = func(state, *args, **kwargs)

        # è¿½è¸ªå˜åŒ–
        changes = {}
        for key in set(initial_state.keys()) | set(result.keys()):
            old_val = initial_state.get(key)
            new_val = result.get(key)
            if old_val != new_val:
                changes[key] = {"old": old_val, "new": new_val}

        if changes:
            logger.debug(f"çŠ¶æ€å˜åŒ–: {changes}")

        logger.debug(f"æ‰§è¡Œ {func.__name__} åçŠ¶æ€: {result}")

        return result

    return wrapper

@trace_state_changes
def traced_node(state: WorkflowState) -> WorkflowState:
    """å¸¦çŠ¶æ€è¿½è¸ªçš„èŠ‚ç‚¹"""
    return process_with_tracing(state)

# æ–­ç‚¹è°ƒè¯•
def debug_workflow_execution(workflow, initial_state: Dict[str, Any]):
    """è°ƒè¯•å·¥ä½œæµæ‰§è¡Œ"""
    print(f"å¼€å§‹è°ƒè¯•å·¥ä½œæµ...")
    print(f"åˆå§‹çŠ¶æ€: {initial_state}")

    # æµå¼æ‰§è¡Œä»¥è§‚å¯Ÿæ¯ä¸€æ­¥
    for step in workflow.stream(initial_state):
        node_name = list(step.keys())[0]
        node_state = step[node_name]

        print(f"\n=== {node_name} ===")
        print(f"çŠ¶æ€: {node_state}")

        # å…è®¸ç”¨æˆ·åœ¨æ¯ä¸ªæ­¥éª¤è®¾ç½®æ–­ç‚¹
        user_input = input("ç»§ç»­? (y/n/q): ")
        if user_input.lower() == 'q':
            print("è°ƒè¯•ç»“æŸ")
            break
        elif user_input.lower() == 'n':
            print("è·³è¿‡åˆ°ä¸‹ä¸€æ­¥")
            continue
```

### Q2: å¦‚ä½•å¤„ç†é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ï¼Ÿ

```python
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor

async def async_research_node(state: WorkflowState) -> WorkflowState:
    """å¼‚æ­¥ç ”ç©¶èŠ‚ç‚¹"""
    topics = state.get("research_topics", [])

    if not topics:
        return {
            **state,
            "current_step": "async_research",
            "messages": state["messages"] + ["æ²¡æœ‰ç ”ç©¶ä¸»é¢˜"]
        }

    # å¼‚æ­¥æ‰§è¡Œå¤šä¸ªç ”ç©¶ä»»åŠ¡
    async with aiohttp.ClientSession() as session:
        tasks = [
            research_topic_async(topic, session)
            for topic in topics
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

    research_results = {}
    for topic, result in zip(topics, results):
        if isinstance(result, Exception):
            research_results[topic] = {"error": str(result)}
        else:
            research_results[topic] = result

    return {
        **state,
        "current_step": "async_research",
        "research_results": research_results,
        "messages": state["messages"] + [
            f"å¼‚æ­¥ç ”ç©¶å®Œæˆï¼Œå¤„ç†äº†{len(topics)}ä¸ªä¸»é¢˜"
        ]
    }

async def research_topic_async(topic: str, session: aiohttp.ClientSession) -> Dict[str, Any]:
    """å¼‚æ­¥ç ”ç©¶å•ä¸ªä¸»é¢˜"""
    try:
        # æ¨¡æ‹ŸAPIè°ƒç”¨
        async with session.get(f"https://api.example.com/research/{topic}") as response:
            data = await response.json()
            return data
    except Exception as e:
        raise Exception(f"ç ”ç©¶ä¸»é¢˜ '{topic}' å¤±è´¥: {e}")

# é•¿æ—¶é—´è¿è¡Œä»»åŠ¡çš„æ£€æŸ¥ç‚¹æœºåˆ¶
def create_checkpoint_workflow():
    """åˆ›å»ºå¸¦æ£€æŸ¥ç‚¹çš„å·¥ä½œæµ"""
    graph = StateGraph(CheckpointState)

    graph.add_node("long_task", long_running_task_node)
    graph.add_node("checkpoint", checkpoint_node)
    graph.add_node("resume", resume_task_node)
    graph.add_node("finalize", finalize_node)

    graph.set_entry_point("long_task")
    graph.add_edge("long_task", "checkpoint")
    graph.add_edge("checkpoint", "resume")
    graph.add_edge("resume", "finalize")
    graph.add_edge("finalize", END)

    return graph.compile()

class CheckpointState(TypedDict):
    current_step: str
    task_id: str
    progress: float
    partial_results: Dict[str, Any]
    checkpoint_data: Dict[str, Any]
    is_resuming: bool

def long_running_task_node(state: CheckpointState) -> CheckpointState:
    """é•¿æ—¶é—´è¿è¡Œä»»åŠ¡èŠ‚ç‚¹"""
    task_id = state["task_id"]
    total_steps = state.get("total_steps", 100)

    # æ¨¡æ‹Ÿé•¿æ—¶é—´ä»»åŠ¡ï¼Œæ¯10æ­¥ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
    for step in range(1, total_steps + 1):
        # æ‰§è¡Œå·¥ä½œå•å…ƒ
        process_work_unit(task_id, step)

        # æ¯10æ­¥ä¿å­˜æ£€æŸ¥ç‚¹
        if step % 10 == 0:
            progress = step / total_steps

            checkpoint_data = {
                "task_id": task_id,
                "current_step": step,
                "progress": progress,
                "partial_results": get_partial_results(task_id, step),
                "timestamp": datetime.now().isoformat()
            }

            # ä¿å­˜æ£€æŸ¥ç‚¹
            save_checkpoint(task_id, checkpoint_data)

            # æ›´æ–°çŠ¶æ€
            state = {
                **state,
                "current_step": "checkpoint",
                "progress": progress,
                "checkpoint_data": checkpoint_data,
                "messages": state["messages"] + [
                    f"æ£€æŸ¥ç‚¹å·²ä¿å­˜ï¼Œè¿›åº¦: {progress:.1%}"
                ]
            }

            return state  # æš‚åœæ‰§è¡Œ

    # ä»»åŠ¡å®Œæˆ
    return {
        **state,
        "current_step": "long_task",
        "progress": 1.0,
        "final_results": get_final_results(task_id),
        "messages": state["messages"] + ["é•¿æ—¶é—´ä»»åŠ¡å®Œæˆ"]
    }

def resume_task_node(state: CheckpointState) -> CheckpointState:
    """æ¢å¤ä»»åŠ¡èŠ‚ç‚¹"""
    checkpoint_data = state["checkpoint_data"]
    task_id = checkpoint_data["task_id"]

    # ä»æ£€æŸ¥ç‚¹æ¢å¤
    start_step = checkpoint_data["current_step"]
    remaining_steps = state.get("total_steps", 100) - start_step

    # ç»§ç»­æ‰§è¡Œå‰©ä½™å·¥ä½œ
    for step in range(start_step + 1, start_step + remaining_steps + 1):
        process_work_unit(task_id, step)

        # æ¯10æ­¥ä¿å­˜æ£€æŸ¥ç‚¹
        if step % 10 == 0:
            progress = step / state.get("total_steps", 100)

            return {
                **state,
                "current_step": "checkpoint",
                "progress": progress,
                "messages": state["messages"] + [
                    f"ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼Œè¿›åº¦: {progress:.1%}"
                ]
            }

    # ä»»åŠ¡å®Œæˆ
    return {
        **state,
        "current_step": "resume",
        "progress": 1.0,
        "final_results": get_final_results(task_id),
        "messages": state["messages"] + ["ä»»åŠ¡æ¢å¤å¹¶å®Œæˆ"]
    }
```

### Q3: å¦‚ä½•ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Ÿ

```python
import gc
from typing import Iterator

class MemoryEfficientWorkflow:
    """å†…å­˜é«˜æ•ˆçš„å·¥ä½œæµ"""

    def __init__(self):
        self.state_history = []
        self.max_history = 10  # åªä¿ç•™æœ€è¿‘10ä¸ªçŠ¶æ€

    def stream_with_cleanup(self, initial_state: Dict[str, Any]) -> Iterator[Dict[str, Any]]:
        """æµå¼æ‰§è¡Œå¹¶æ¸…ç†å†…å­˜"""
        current_state = initial_state.copy()

        for step_name, step_state in self._execute_steps(current_state):
            # æ›´æ–°çŠ¶æ€å†å²
            self.state_history.append({
                "step": step_name,
                "state": step_state.copy(),
                "timestamp": datetime.now().isoformat()
            })

            # é™åˆ¶å†å²è®°å½•æ•°é‡
            if len(self.state_history) > self.max_history:
                self.state_history.pop(0)

            # æ¸…ç†å¤§å‹å¯¹è±¡
            self._cleanup_large_objects(step_state)

            yield {step_name: step_state}

    def _cleanup_large_objects(self, state: Dict[str, Any]):
        """æ¸…ç†å¤§å‹å¯¹è±¡"""
        # å°†å¤§å‹ç»“æœè½¬æ¢ä¸ºå¼•ç”¨
        for key, value in state.items():
            if isinstance(value, list) and len(value) > 1000:
                # å¤§åˆ—è¡¨è½¬æ¢ä¸ºåˆ†å—
                state[key] = {
                    "type": "chunked_list",
                    "chunk_size": 100,
                    "total_count": len(value),
                    "chunks": [value[i:i+100] for i in range(0, len(value), 100)]
                }
            elif isinstance(value, dict) and len(str(value)) > 10000:
                # å¤§å­—å…¸å‹ç¼©
                state[key] = {
                    "type": "compressed_dict",
                    "compressed": True,
                    "keys": list(value.keys())[:10],  # åªä¿ç•™å‰10ä¸ªé”®
                    "total_keys": len(value)
                }

    def get_state_summary(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–çŠ¶æ€æ‘˜è¦"""
        summary = {
            "current_step": state.get("current_step", "unknown"),
            "step_count": state.get("step_count", 0),
            "message_count": len(state.get("messages", [])),
            "data_size": self._estimate_data_size(state)
        }

        # æ·»åŠ å…³é”®æŒ‡æ ‡
        if "confidence" in state:
            summary["confidence"] = state["confidence"]
        if "error_count" in state:
            summary["error_count"] = state["error_count"]

        return summary

    def _estimate_data_size(self, state: Dict[str, Any]) -> str:
        """ä¼°ç®—æ•°æ®å¤§å°"""
        import sys

        size_bytes = sys.getsizeof(str(state))

        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        else:
            return f"{size_bytes / (1024 * 1024):.1f} MB"

# ä½¿ç”¨å†…å­˜ç›‘æ§
def memory_monitored_node(state: WorkflowState) -> WorkflowState:
    """å¸¦å†…å­˜ç›‘æ§çš„èŠ‚ç‚¹"""
    import psutil
    import os

    process = psutil.Process(os.getpid())
    memory_before = process.memory_info().rss / 1024 / 1024  # MB

    # æ‰§è¡Œä¸»è¦é€»è¾‘
    result = perform_memory_intensive_operation(state)

    memory_after = process.memory_info().rss / 1024 / 1024  # MB
    memory_delta = memory_after - memory_before

    return {
        **state,
        "current_step": "processed",
        "result": result,
        "memory_usage": {
            "before_mb": memory_before,
            "after_mb": memory_after,
            "delta_mb": memory_delta
        },
        "messages": state["messages"] + [
            f"å†…å­˜ä½¿ç”¨: {memory_delta:.1f}MB"
        ]
    }
```

### Q4: å¦‚ä½•å®ç°è‡ªå®šä¹‰èŠ‚ç‚¹ç±»å‹ï¼Ÿ

```python
from abc import ABC, abstractmethod
from typing import TypeVar, Generic

T = TypeVar('T')

class BaseCustomNode(ABC, Generic[T]):
    """è‡ªå®šä¹‰èŠ‚ç‚¹åŸºç±»"""

    def __init__(self, name: str, config: Dict[str, Any]):
        self.name = name
        self.config = config
        self.state_schema = config.get("state_schema", {})

    @abstractmethod
    def process(self, state: T) -> T:
        """å¤„ç†çŠ¶æ€"""
        pass

    @abstractmethod
    def validate_state(self, state: T) -> bool:
        """éªŒè¯çŠ¶æ€"""
        pass

    def pre_process(self, state: T) -> T:
        """é¢„å¤„ç†é’©å­"""
        return state

    def post_process(self, state: T) -> T:
        """åå¤„ç†é’©å­"""
        return state

    def handle_error(self, state: T, error: Exception) -> T:
        """é”™è¯¯å¤„ç†é’©å­"""
        return {
            **state,
            "current_step": f"{self.name}_error",
            "error": str(error),
            "messages": state.get("messages", []) + [f"{self.name}é”™è¯¯: {error}"]
        }

class DataValidationNode(BaseCustomNode[WorkflowState]):
    """æ•°æ®éªŒè¯èŠ‚ç‚¹"""

    def __init__(self, config: Dict[str, Any]):
        super().__init__("data_validation", config)
        self.validation_rules = config.get("validation_rules", {})

    def process(self, state: WorkflowState) -> WorkflowState:
        """æ‰§è¡Œæ•°æ®éªŒè¯"""
        try:
            # é¢„å¤„ç†
            state = self.pre_process(state)

            # æ‰§è¡ŒéªŒè¯
            validation_results = self._validate_data(state)

            # åå¤„ç†
            state = self.post_process(state)

            return {
                **state,
                "current_step": "validation",
                "validation_results": validation_results,
                "is_valid": validation_results["is_valid"],
                "messages": state["messages"] + ["æ•°æ®éªŒè¯å®Œæˆ"]
            }

        except Exception as e:
            return self.handle_error(state, e)

    def validate_state(self, state: WorkflowState) -> bool:
        """éªŒè¯çŠ¶æ€æ ¼å¼"""
        required_fields = ["user_input", "current_step"]
        return all(field in state for field in required_fields)

    def _validate_data(self, state: WorkflowState) -> Dict[str, Any]:
        """æ‰§è¡Œå…·ä½“çš„æ•°æ®éªŒè¯"""
        user_input = state.get("user_input", "")

        results = {
            "is_valid": True,
            "errors": [],
            "warnings": [],
            "confidence": 0.0
        }

        # é•¿åº¦æ£€æŸ¥
        if len(user_input) < 3:
            results["errors"].append("è¾“å…¥å¤ªçŸ­")
            results["is_valid"] = False

        # å†…å®¹æ£€æŸ¥
        if not user_input.strip():
            results["errors"].append("è¾“å…¥ä¸ºç©º")
            results["is_valid"] = False

        # è®¡ç®—ç½®ä¿¡åº¦
        if results["is_valid"]:
            results["confidence"] = min(len(user_input) / 100.0, 1.0)

        return results

# è‡ªå®šä¹‰èŠ‚ç‚¹å·¥å‚
class CustomNodeFactory:
    """è‡ªå®šä¹‰èŠ‚ç‚¹å·¥å‚"""

    _node_types = {
        "data_validation": DataValidationNode,
        # å¯ä»¥æ·»åŠ æ›´å¤šèŠ‚ç‚¹ç±»å‹
    }

    @classmethod
    def create_node(cls, node_type: str, name: str, config: Dict[str, Any]) -> BaseCustomNode:
        """åˆ›å»ºè‡ªå®šä¹‰èŠ‚ç‚¹"""
        if node_type not in cls._node_types:
            raise ValueError(f"æœªçŸ¥çš„èŠ‚ç‚¹ç±»å‹: {node_type}")

        node_class = cls._node_types[node_type]
        return node_class(config)

    @classmethod
    def register_node_type(cls, node_type: str, node_class: type):
        """æ³¨å†Œæ–°çš„èŠ‚ç‚¹ç±»å‹"""
        cls._node_types[node_type] = node_class

# ä½¿ç”¨è‡ªå®šä¹‰èŠ‚ç‚¹
def create_custom_workflow():
    """åˆ›å»ºä½¿ç”¨è‡ªå®šä¹‰èŠ‚ç‚¹çš„å·¥ä½œæµ"""
    graph = StateGraph(WorkflowState)

    # åˆ›å»ºè‡ªå®šä¹‰èŠ‚ç‚¹
    validation_node = CustomNodeFactory.create_node(
        "data_validation",
        "input_validation",
        {"validation_rules": {"min_length": 3}}
    )

    # å°†è‡ªå®šä¹‰èŠ‚ç‚¹åŒ…è£…ä¸ºLangGraphèŠ‚ç‚¹
    def validation_wrapper(state: WorkflowState) -> WorkflowState:
        return validation_node.process(state)

    # æ·»åŠ åˆ°å›¾
    graph.add_node("validate", validation_wrapper)

    # è®¾ç½®æµç¨‹
    graph.set_entry_point("validate")
    graph.add_edge("validate", END)

    return graph.compile()
```

### Q5: å¦‚ä½•é›†æˆå¤–éƒ¨ç³»ç»Ÿï¼Ÿ

```python
import asyncio
import aiohttp
from dataclasses import dataclass
from typing import Optional, Dict, Any

@dataclass
class ExternalSystemConfig:
    """å¤–éƒ¨ç³»ç»Ÿé…ç½®"""
    name: str
    base_url: str
    auth_token: str
    timeout: int = 30
    retry_count: int = 3

class ExternalSystemConnector:
    """å¤–éƒ¨ç³»ç»Ÿè¿æ¥å™¨"""

    def __init__(self, config: ExternalSystemConfig):
        self.config = config
        self.session: Optional[aiohttp.ClientSession] = None

    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=self.config.timeout)
        )
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()

    async def call_api(self, endpoint: str, method: str = "GET", data: Optional[Dict] = None) -> Dict[str, Any]:
        """è°ƒç”¨å¤–éƒ¨API"""
        url = f"{self.config.base_url}/{endpoint}"
        headers = {"Authorization": f"Bearer {self.config.auth_token}"}

        for attempt in range(self.config.retry_count):
            try:
                async with self.session.request(method, url, json=data, headers=headers) as response:
                    response.raise_for_status()
                    return await response.json()

            except aiohttp.ClientError as e:
                if attempt == self.config.retry_count - 1:
                    raise ExternalAPIError(f"APIè°ƒç”¨å¤±è´¥: {e}")
                await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿

    async def get_customer_info(self, customer_id: str) -> Dict[str, Any]:
        """è·å–å®¢æˆ·ä¿¡æ¯"""
        return await self.call_api(f"customers/{customer_id}")

    async def update_case_status(self, case_id: str, status: str) -> Dict[str, Any]:
        """æ›´æ–°æ¡ˆä¾‹çŠ¶æ€"""
        return await self.call_api(f"cases/{case_id}/status", "PUT", {"status": status})

class ExternalAPIError(Exception):
    """å¤–éƒ¨APIé”™è¯¯"""
    pass

def create_external_integration_workflow():
    """åˆ›å»ºå¤–éƒ¨ç³»ç»Ÿé›†æˆå·¥ä½œæµ"""
    graph = StateGraph(ExternalIntegrationState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("fetch_customer", fetch_customer_node)
    graph.add_node("process_request", process_request_node)
    graph.add_node("update_external_system", update_external_system_node)
    graph.add_node("sync_data", sync_data_node)

    graph.set_entry_point("fetch_customer")
    graph.add_edge("fetch_customer", "process_request")
    graph.add_edge("process_request", "update_external_system")
    graph.add_edge("update_external_system", "sync_data")
    graph.add_edge("sync_data", END)

    return graph.compile()

class ExternalIntegrationState(TypedDict):
    current_step: str
    messages: Annotated[List[str], operator.add]

    # å®¢æˆ·ä¿¡æ¯
    customer_id: str
    customer_info: Optional[Dict[str, Any]]

    # è¯·æ±‚ä¿¡æ¯
    request_data: Dict[str, Any]
    processing_result: Optional[Dict[str, Any]]

    # å¤–éƒ¨ç³»ç»Ÿ
    external_case_id: Optional[str]
    external_status: Optional[str]

    # åŒæ­¥çŠ¶æ€
    sync_status: str
    sync_errors: List[str]

async def fetch_customer_node(state: ExternalIntegrationState) -> ExternalIntegrationState:
    """è·å–å®¢æˆ·ä¿¡æ¯èŠ‚ç‚¹"""
    customer_id = state["customer_id"]

    # å¤–éƒ¨ç³»ç»Ÿé…ç½®
    external_config = ExternalSystemConfig(
        name="crm_system",
        base_url="https://api.crm.example.com",
        auth_token="your_auth_token"
    )

    try:
        async with ExternalSystemConnector(external_config) as connector:
            customer_info = await connector.get_customer_info(customer_id)

        return {
            **state,
            "current_step": "fetch_customer",
            "customer_info": customer_info,
            "messages": state["messages"] + [f"è·å–å®¢æˆ·ä¿¡æ¯æˆåŠŸ: {customer_id}"]
        }

    except ExternalAPIError as e:
        return {
            **state,
            "current_step": "fetch_customer_error",
            "customer_info": None,
            "messages": state["messages"] + [f"è·å–å®¢æˆ·ä¿¡æ¯å¤±è´¥: {e}"]
        }

async def update_external_system_node(state: ExternalIntegrationState) -> ExternalIntegrationState:
    """æ›´æ–°å¤–éƒ¨ç³»ç»ŸèŠ‚ç‚¹"""
    processing_result = state.get("processing_result", {})
    customer_id = state["customer_id"]

    # å¤–éƒ¨ç³»ç»Ÿé…ç½®
    external_config = ExternalSystemConfig(
        name="workflow_system",
        base_url="https://api.workflow.example.com",
        auth_token="your_workflow_token"
    )

    try:
        async with ExternalSystemConnector(external_config) as connector:
            # åˆ›å»ºæ¡ˆä¾‹
            case_data = {
                "customer_id": customer_id,
                "request_type": processing_result.get("type"),
                "priority": processing_result.get("priority"),
                "description": processing_result.get("description")
            }

            case_result = await connector.call_api("cases", "POST", case_data)

            # æ›´æ–°æ¡ˆä¾‹çŠ¶æ€
            await connector.update_case_status(case_result["id"], "processing")

        return {
            **state,
            "current_step": "update_external",
            "external_case_id": case_result["id"],
            "external_status": "processing",
            "messages": state["messages"] + [f"å¤–éƒ¨ç³»ç»Ÿæ›´æ–°æˆåŠŸ: {case_result['id']}"]
        }

    except ExternalAPIError as e:
        return {
            **state,
            "current_step": "update_external_error",
            "external_case_id": None,
            "sync_errors": state.get("sync_errors", []) + [str(e)],
            "messages": state["messages"] + [f"å¤–éƒ¨ç³»ç»Ÿæ›´æ–°å¤±è´¥: {e}"]
        }
```

---

## ğŸ“š æ‰©å±•èµ„æº

### å®˜æ–¹æ–‡æ¡£å’Œèµ„æº
- [LangGraphå®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [LangGraph GitHubä»“åº“](https://github.com/langchain-ai/langgraph)
- [LangGraph APIå‚è€ƒ](https://langchain-ai.github.io/langgraph/reference/)

### æ•™ç¨‹å’Œç¤ºä¾‹
- [LangGraphæ•™ç¨‹](https://langchain-ai.github.io/langgraph/tutorials/)
- [æ„å»ºå¤šAgentåº”ç”¨](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/)
- [å·¥ä½œæµçŠ¶æ€ç®¡ç†](https://langchain-ai.github.io/langgraph/tutorials/state_management/)

### ç¤¾åŒºèµ„æº
- [LangChain Discord](https://discord.gg/langchain)
- [LangSmithæ–‡æ¡£](https://smith.langchain.com/)
- [ç¤ºä¾‹åº“](https://github.com/langchain-ai/langgraph/tree/main/examples)

### ç›¸å…³æŠ€æœ¯
- [State Machines](https://en.wikipedia.org/wiki/Finite-state_machine)
- [Workflow Engines](https://en.wikipedia.org/wiki/Workflow_engine)
- [Graph Theory](https://en.wikipedia.org/wiki/Graph_theory)

### æ¨èé˜…è¯»
- "Designing Data-Intensive Applications" by Martin Kleppmann
- "Building Microservices" by Sam Newman
- "Domain-Driven Design" by Eric Evans

---

*æœ¬æ•™ç¨‹å°†æŒç»­æ›´æ–°ï¼Œæ¶µç›–LangGraphçš„æœ€æ–°åŠŸèƒ½å’Œæœ€ä½³å®è·µã€‚*

**åˆ›å»ºæ—¶é—´**: 2026-02-06
**æœ€åæ›´æ–°**: 2026-02-06
**ç‰ˆæœ¬**: v0.1