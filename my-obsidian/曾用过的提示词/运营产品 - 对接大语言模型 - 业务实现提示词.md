你是一名 **资深 AI 应用工程师 + 运营领域 Prompt 设计者**。

当前后端工程已经具备：

- FastAPI 业务逻辑（文档 / 版本 / chat）
    
- 一个 **完整但尚未承载业务的 LLM 架构层**：
    
    - `llm.base`
        
    - `llm.types`
        
    - `llm.registry`
        
    - `llm.providers.*`
        

现在请你 **只完成“业务 Prompt 实现”这一件事**。

---

## ⚠️ 总体原则（必须遵守）

1. **不修改 LLM 架构设计**
    
2. **不新增新的 Provider 类型**
    
3. **不引入新的工程抽象**
    
4. **Prompt 是业务资产，不是基础设施**
    

---

## 一、你要解决的业务问题（明确）

> 用户在对话区输入一段自然语言  
> → 系统将其理解为「对当前运营策划文档的修改要求」  
> → 大模型返回 **修改后的完整 Markdown 文档**

---

## 二、允许你做的工程改动范围（非常重要）

你**只能**在以下范围内工作：

### ✅ 允许

- 新增 **业务 Prompt 构建函数**
    
- 在 `llm_service.py` 中：
    
    - 使用已有 LLM 接口
        
    - 调用 `llm.generate(...)`
        
- 让 `/chat` 真正走大模型
    

### ❌ 不允许

- 改 LLM 抽象接口
    
- 改 Provider 选择逻辑
    
- 把 Prompt 写死在 API 层
    
- 把 Prompt 写进 Provider
    

---

## 三、Prompt 的工程落位（必须这样做）

请新增一个**明确的业务 Prompt 模块**：

`src/app/prompts/ ├── __init__.py └── document_edit.py`

该文件 **只负责一件事**：

> 根据「当前 Markdown + 用户输入」，构造一个 **运营策划文档修改 Prompt**

---

## 四、Prompt 内容要求（必须原样遵守）

### Prompt 模板（核心）

`你是一名资深的运营策划专家。  下面是当前的运营策划文档（Markdown 格式）： -------------------- {current_markdown} --------------------  用户提出了新的修改要求： -------------------- {user_input} --------------------  请你根据用户的要求，对上述运营策划文档进行修改。  要求： 1. 尽量保持原有文档结构与已有内容不变 2. 只在必要的地方进行补充、修改或调整 3. 输出【修改后的完整 Markdown 文档】 4. 不要输出任何解释、说明、分析或多余文字 5. 不要使用代码块包裹 Markdown 内容  现在请直接输出最终的 Markdown 文档：`

⚠️ 注意：  
这是 **业务 Prompt 的“第一版”**，  
不做 patch、不做 diff、不做结构锁定。

---

## 五、llm_service.py 中的职责调整（关键）

你需要：

1. 引入 `prompts.document_edit`
    
2. 将 Prompt 构建逻辑 **从 chat API 中移出**
    
3. 在 `llm_service.py` 中形成类似流程：
    

`prompt = build_document_edit_prompt(     current_markdown=...,     user_input=... )  response = llm.generate(prompt)  return response.text`

---

## 六、与现有业务逻辑的对接方式

### `/chat` 接口现在应当：

1. 读取当前 Document Markdown
    
2. 调用 `llm_service.generate_updated_document(...)`
    
3. 得到 **完整 Markdown**
    
4. 走原有版本保存逻辑（不改）
    
5. 返回最新 Markdown
    

⚠️ **版本逻辑不要动一行**

---

## 七、Mock / Placeholder 行为要求

即使使用：

- `MockLLM`
    
- `PlaceholderLLM`
    

也必须保证：

- 返回的内容 **看起来像 Markdown**
    
- 能被版本系统正常保存
    
- 不破坏前端展示
    

---

## 八、代码注释要求（非常重要）

在以下地方必须写注释：

1. `document_edit.py`
    
    > 这是“运营策划文档修改”的业务 Prompt，不属于 LLM 基础设施
    
2. `llm_service.py`
    
    > 这里是业务与 LLM 架构的连接点
    

---

## 九、验收标准（你必须确保）

> 在当前 Provider = mock / placeholder 的情况下：

- `/chat` 接口：
    
    - 不再返回假字符串
        
    - 而是返回 **来自 LLM 的 Markdown 文本**
        
- 前端：
    
    - 对话一次
        
    - Markdown 文档被整体替换
        
- 版本：
    
    - 正常生成新版本
        
    - diff 合理
        

---

## 十、工程哲学（这一步很重要）

- Prompt 是 **业务逻辑**
    
- Prompt 会迭代、会试错、会推翻
    
- 所以它：
    
    - 必须 **可读**
        
    - 必须 **集中**
        
    - 必须 **不和基础设施耦合**
        

你现在做的，是在为后面这些事情铺路：

- Prompt A/B Test
    
- 多 Prompt 策略
    
- Agent 拆分（分析 / 修改 / 校验）